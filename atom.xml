<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Product Intelligence — GenAI Knowledge Base</title>
  <subtitle>Curated daily intelligence on generative AI: tools, research, strategy, industry moves. 4,600+ entries from 41 RSS feeds, Reddit, X bookmarks, and Brave Search.</subtitle>
  <link href="https://fr491l3b0t.github.io/kanban/genai-kb-editorial.html" rel="alternate" type="text/html"/>
  <link href="https://fr491l3b0t.github.io/kanban/atom.xml" rel="self" type="application/atom+xml"/>
  <id>https://fr491l3b0t.github.io/kanban/genai-kb-editorial.html</id>
  <updated>2026-02-28T08:03:12.156Z</updated>
  <author>
    <name>Raphael Ruz</name>
  </author>
  <rights>© 2026 Raphael Ruz</rights>
  <generator>Product Intelligence KB Feed Builder</generator>
  <entry>
    <title>Google puts users at risk by downplaying health disclaimers under AI Overviews</title>
    <link href="https://www.theguardian.com/technology/2026/feb/16/google-puts-users-at-risk-downplaying-disclaimers-ai-overviews" rel="alternate" type="text/html"/>
    <id>https://www.theguardian.com/technology/2026/feb/16/google-puts-users-at-risk-downplaying-disclaimers-ai-overviews</id>
    <updated>2026-02-16T07:30:13.000Z</updated>
    <category term="ethics-regulation" label="Ethics &amp; Regulation"/>
    <summary type="html"><![CDATA[Exclusive: Google fails to include safety warnings when users are first presented with AI-generated medical adviceGoogle is putting people at risk of harm by downplaying safety warnings that its AI-generated medical advice may be wrong.When answering queries about sensitive…]]></summary>
    <source><title>Guardian AI</title></source>
  </entry>
  <entry>
    <title>[D] “I Was Told There Would Be No Math” Why many ML projects fail before the model</title>
    <link href="https://www.reddit.com/r/MachineLearning/comments/1r61vx9/d_i_was_told_there_would_be_no_math_why_many_ml/" rel="alternate" type="text/html"/>
    <id>https://www.reddit.com/r/MachineLearning/comments/1r61vx9/d_i_was_told_there_would_be_no_math_why_many_ml/</id>
    <updated>2026-02-16T06:12:42.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[I have been doing machine learning for less than a year. My background is 25 years as a technical architect across financial services, healthcare, and education. I have worked on fixed income risk analytics, mortgage modeling using Monte Carlo simulation, Medicaid and Medicare…]]></summary>
    <source><title>r/MachineLearning</title></source>
  </entry>
  <entry>
    <title>A Machine Learning Approach to the Nirenberg Problem</title>
    <link href="https://arxiv.org/abs/2602.12368" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12368</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12368v1 Announce Type: new Abstract: This work introduces the Nirenberg Neural Network: a numerical approach to the Nirenberg problem of prescribing Gaussian curvature on $S^2$ for metrics that are pointwise conformal to the round metric. Our mesh-free…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>Synthetic Interaction Data for Scalable Personalization in Large Language Models</title>
    <link href="https://arxiv.org/abs/2602.12394" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12394</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12394v1 Announce Type: new Abstract: Personalized prompting offers large opportunities for deploying large language models (LLMs) to diverse users, yet existing prompt optimization methods primarily focus on task-level optimization while largely overlooking…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>Intrinsic Credit Assignment for Long Horizon Interaction</title>
    <link href="https://arxiv.org/abs/2602.12342" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12342</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12342v1 Announce Type: new Abstract: How can we train agents to navigate uncertainty over long horizons? In this work, we propose {\Delta}Belief-RL, which leverages a language model's own intrinsic beliefs to reward intermediate progress. Our method utilizes the…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>Value Bonuses using Ensemble Errors for Exploration in Reinforcement Learning</title>
    <link href="https://arxiv.org/abs/2602.12375" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12375</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12375v1 Announce Type: new Abstract: Optimistic value estimates provide one mechanism for directed exploration in reinforcement learning (RL). The agent acts greedily with respect to an estimate of the value plus what can be seen as a value bonus. The value bonus can…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>TFT-ACB-XML: Decision-Level Integration of Customized Temporal Fusion Transformer and Attention-BiLSTM with XGBoost Meta-Learner for BTC Price Forecasting</title>
    <link href="https://arxiv.org/abs/2602.12380" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12380</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12380v1 Announce Type: new Abstract: Accurate forecasting of Bitcoin (BTC) has always been a challenge because decentralized markets are non-linear, highly volatile, and have temporal irregularities. Existing deep learning models often struggle with interpretability…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>Rational Neural Networks have Expressivity Advantages</title>
    <link href="https://arxiv.org/abs/2602.12390" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12390</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12390v1 Announce Type: new Abstract: We study neural networks with trainable low-degree rational activation functions and show that they are more expressive and parameter-efficient than modern piecewise-linear and smooth activations such as ELU, LeakyReLU, LogSigmoid,…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>OptiML: An End-to-End Framework for Program Synthesis and CUDA Kernel Optimization</title>
    <link href="https://arxiv.org/abs/2602.12305" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12305</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12305v1 Announce Type: new Abstract: Generating high-performance CUDA kernels remains challenging due to the need to navigate a combinatorial space of low-level transformations under noisy and expensive hardware feedback. Although large language models can synthesize…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>Abstractive Red-Teaming of Language Model Character</title>
    <link href="https://arxiv.org/abs/2602.12318" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12318</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12318v1 Announce Type: new Abstract: We want language model assistants to conform to a character specification, which asserts how the model should act across diverse user interactions. While models typically follow these character specifications, they can occasionally…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>The Appeal and Reality of Recycling LoRAs with Adaptive Merging</title>
    <link href="https://arxiv.org/abs/2602.12323" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12323</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12323v1 Announce Type: new Abstract: The widespread availability of fine-tuned LoRA modules for open pre-trained models has led to an interest in methods that can adaptively merge LoRAs to improve performance. These methods typically include some way of selecting…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>Policy4OOD: A Knowledge-Guided World Model for Policy Intervention Simulation against the Opioid Overdose Crisis</title>
    <link href="https://arxiv.org/abs/2602.12373" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12373</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12373v1 Announce Type: new Abstract: The opioid epidemic remains one of the most severe public health crises in the United States, yet evaluating policy interventions before implementation is difficult: multiple policies interact within a dynamic system where…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>Deep Doubly Debiased Longitudinal Effect Estimation with ICE G-Computation</title>
    <link href="https://arxiv.org/abs/2602.12379" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12379</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12379v1 Announce Type: new Abstract: Estimating longitudinal treatment effects is essential for sequential decision-making but is challenging due to treatment-confounder feedback. While Iterative Conditional Expectation (ICE) G-computation offers a principled…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>Why Deep Jacobian Spectra Separate: Depth-Induced Scaling and Singular-Vector Alignment</title>
    <link href="https://arxiv.org/abs/2602.12384" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12384</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12384v1 Announce Type: new Abstract: Understanding why gradient-based training in deep networks exhibits strong implicit bias remains challenging, in part because tractable singular-value dynamics are typically available only for balanced deep linear models. We…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>High-dimensional Level Set Estimation with Trust Regions and Double Acquisition Functions</title>
    <link href="https://arxiv.org/abs/2602.12391" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12391</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12391v1 Announce Type: new Abstract: Level set estimation (LSE) classifies whether an unknown function's value exceeds a specified threshold for given inputs, a fundamental problem in many real-world applications. In active learning settings with limited initial data,…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>AstRL: Analog and Mixed-Signal Circuit Synthesis with Deep Reinforcement Learning</title>
    <link href="https://arxiv.org/abs/2602.12402" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12402</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12402v1 Announce Type: new Abstract: Analog and mixed-signal (AMS) integrated circuits (ICs) lie at the core of modern computing and communications systems. However, despite the continued rise in design complexity, advances in AMS automation remain limited. This…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs</title>
    <link href="https://arxiv.org/abs/2602.12705" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12705</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12705v1 Announce Type: new Abstract: We present MedXIAOHE, a medical vision-language foundation model designed to advance general-purpose medical understanding and reasoning in real-world clinical applications. MedXIAOHE achieves state-of-the-art performance across…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>ReFilter: Improving Robustness of Retrieval-Augmented Generation via Gated Filter</title>
    <link href="https://arxiv.org/abs/2602.12709" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12709</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12709v1 Announce Type: new Abstract: Retrieval-augmented generation (RAG) has become a dominant paradigm for grounding large language models (LLMs) with external evidence in knowledge-intensive question answering. A core design choice is how to fuse retrieved samples…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>Evaluating Robustness of Reasoning Models on Parameterized Logical Problems</title>
    <link href="https://arxiv.org/abs/2602.12665" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12665</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12665v1 Announce Type: new Abstract: Logic provides a controlled testbed for evaluating LLM-based reasoners, yet standard SAT-style benchmarks often conflate surface difficulty (length, wording, clause order) with the structural phenomena that actually determine…]]></summary>
    <source><title>arXiv cs.AI</title></source>
  </entry>
  <entry>
    <title>X-SYS: A Reference Architecture for Interactive Explanation Systems</title>
    <link href="https://arxiv.org/abs/2602.12748" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12748</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12748v1 Announce Type: new Abstract: The explainable AI (XAI) research community has proposed numerous technical methods, yet deploying explainability as systems remains challenging: Interactive explanation systems require both suitable algorithms and system…]]></summary>
    <source><title>arXiv cs.AI</title></source>
  </entry>
  <entry>
    <title>Discovering Semantic Latent Structures in Psychological Scales: A Response-Free Pathway to Efficient Simplification</title>
    <link href="https://arxiv.org/abs/2602.12575" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12575</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12575v1 Announce Type: new Abstract: Psychological scale refinement traditionally relies on response-based methods such as factor analysis, item response theory, and network psychometrics to optimize item composition. Although rigorous, these approaches require large…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>$\mathcal{X}$-KD: General Experiential Knowledge Distillation for Large Language Models</title>
    <link href="https://arxiv.org/abs/2602.12674" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.12674</id>
    <updated>2026-02-16T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.12674v1 Announce Type: new Abstract: Knowledge Distillation (KD) for Large Language Models (LLMs) has become increasingly important as models grow in size and complexity. While existing distillation approaches focus on imitating teacher behavior, they often overlook…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>[D] METR TH1.1: “working_time” is wildly different across models. Quick breakdown + questions.</title>
    <link href="https://www.reddit.com/r/MachineLearning/comments/1r60e9a/d_metr_th11_working_time_is_wildly_different/" rel="alternate" type="text/html"/>
    <id>https://www.reddit.com/r/MachineLearning/comments/1r60e9a/d_metr_th11_working_time_is_wildly_different/</id>
    <updated>2026-02-16T04:53:31.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[METR’s Time Horizon benchmark (TH1 / TH1.1) estimates how long a task (in human-expert minutes) a model can complete with 50% reliability. https://preview.redd.it/sow40w7ccsjg1.png?width=1200&format=png&auto=webp&s=ff50a3774cfdc16bc51beedb869f9affda901c9f Most people look at…]]></summary>
    <source><title>r/MachineLearning</title></source>
  </entry>
  <entry>
    <title>As AI data centers hit power limits, Peak XV backs Indian startup C2i to fix the bottleneck</title>
    <link href="https://techcrunch.com/2026/02/15/as-ai-data-centers-hit-power-limits-peak-xv-backs-indian-startup-c2i-to-fix-the-bottleneck/" rel="alternate" type="text/html"/>
    <id>https://techcrunch.com/2026/02/15/as-ai-data-centers-hit-power-limits-peak-xv-backs-indian-startup-c2i-to-fix-the-bottleneck/</id>
    <updated>2026-02-16T01:00:00.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[C2i has raised $15 million as it tests a grid-to-GPU approach to reducing power losses in AI data centers.]]></summary>
    <source><title>TechCrunch AI</title></source>
  </entry>
  <entry>
    <title>Blackstone backs Neysa in up to $1.2B financing as India pushes to build domestic AI infrastructure</title>
    <link href="https://techcrunch.com/2026/02/15/blackstone-backs-neysa-in-up-to-1-2b-financing-as-india-pushes-to-build-domestic-ai-compute/" rel="alternate" type="text/html"/>
    <id>https://techcrunch.com/2026/02/15/blackstone-backs-neysa-in-up-to-1-2b-financing-as-india-pushes-to-build-domestic-ai-compute/</id>
    <updated>2026-02-16T00:30:00.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[Neysa is targeting deployments of more than 20,000 GPUs over time as demand for local AI compute accelerates.]]></summary>
    <source><title>TechCrunch AI</title></source>
  </entry>
  <entry>
    <title>Deflation: Cost to train A.I. models drops 40% per year - Karpathy</title>
    <link href="https://www.reddit.com/r/LocalLLaMA/comments/1r5uhfu/deflation_cost_to_train_ai_models_drops_40_per/" rel="alternate" type="text/html"/>
    <id>https://www.reddit.com/r/LocalLLaMA/comments/1r5uhfu/deflation_cost_to_train_ai_models_drops_40_per/</id>
    <updated>2026-02-16T00:11:13.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[https://github.com/karpathy/nanochat/discussions/481 Quote: ..., each year the cost to train GPT-2 is falling to approximately 40% of the previous year. (I think this is an underestimate and that further improvements are still quite possible). The gains come from everywhere:…]]></summary>
    <source><title>r/LocalLLaMA</title></source>
  </entry>
  <entry>
    <title>[D] Advice on sequential recommendations architectures</title>
    <link href="https://www.reddit.com/r/MachineLearning/comments/1r5u24v/d_advice_on_sequential_recommendations/" rel="alternate" type="text/html"/>
    <id>https://www.reddit.com/r/MachineLearning/comments/1r5u24v/d_advice_on_sequential_recommendations/</id>
    <updated>2026-02-15T23:52:36.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[I've tried to use a Transformer decoder architecture to model a sequence of user actions. Unlike an item_id paradigm where each interaction is described by the id of the item the user interacted with, I need to express the interaction through a series of attributes. For example…]]></summary>
    <source><title>r/MachineLearning</title></source>
  </entry>
  <entry>
    <title>Imandra CodeLogician: LLMs + Formal Methods</title>
    <link href="https://arxiv.org/abs/2601.11840" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2601.11840</id>
    <updated>2026-02-15T22:43:27.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[Comments]]></summary>
    <source><title>Lobsters AI</title></source>
  </entry>
  <entry>
    <title>Makers of AI chatbots that put children at risk face big fines or UK ban</title>
    <link href="https://www.theguardian.com/technology/2026/feb/15/ai-chatbots-children-risk-fines-uk-ban" rel="alternate" type="text/html"/>
    <id>https://www.theguardian.com/technology/2026/feb/15/ai-chatbots-children-risk-fines-uk-ban</id>
    <updated>2026-02-15T22:30:34.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[Starmer to announce ‘crackdown on vile illegal content created by AI’ after scandal involving Elon Musk’s Grok toolMakers of AI chatbots that put children at risk will face massive fines or even see their services blocked in the UK under law changes to be announced by Keir…]]></summary>
    <source><title>Guardian AI</title></source>
  </entry>
  <entry>
    <title>inclusionAI/Ling-2.5-1T · Hugging Face</title>
    <link href="https://www.reddit.com/r/LocalLLaMA/comments/1r5qfb8/inclusionailing251t_hugging_face/" rel="alternate" type="text/html"/>
    <id>https://www.reddit.com/r/LocalLLaMA/comments/1r5qfb8/inclusionailing251t_hugging_face/</id>
    <updated>2026-02-15T21:20:54.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[another 1T model :) from inclusionAI: Ling-2.5-1T, Inclusive Intelligence, Instant Impact. Today, we launch Ling-2.5-1T and make it open source. Thinking models raise the ceiling of intelligence, while instant models expand its reach by balancing efficiency and…]]></summary>
    <source><title>r/LocalLLaMA</title></source>
  </entry>
  <entry>
    <title>[P]ut a Neural Network in VCV Rack 2 and told it to make sounds that influence my emotion tracking module…</title>
    <link href="https://www.reddit.com/r/MachineLearning/comments/1r5ogo5/put_a_neural_network_in_vcv_rack_2_and_told_it_to/" rel="alternate" type="text/html"/>
    <id>https://www.reddit.com/r/MachineLearning/comments/1r5ogo5/put_a_neural_network_in_vcv_rack_2_and_told_it_to/</id>
    <updated>2026-02-15T20:03:24.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[It decided to blow out my right headphone to make me show fear Some Background: I’m working on integrating computer vision and facial tracking into VCV Rack 2 with the goal of, for now, having emotions converted to CV output and granting control over synths. I’ve been adding a…]]></summary>
    <source><title>r/MachineLearning</title></source>
  </entry>
  <entry>
    <title>Show HN: Microgpt is a GPT you can visualize in the browser</title>
    <link href="https://microgpt.boratto.ca" rel="alternate" type="text/html"/>
    <id>https://microgpt.boratto.ca</id>
    <updated>2026-02-15T18:40:35.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[very much inspired by karpathy's microgpt of the same name. it's (by default) a 4000 param GPT/LLM/NN that learns to generate names. this is sorta an educational tool in that you can visualize the activations as they pass through the network, and click on things to get an…]]></summary>
    <source><title>Hacker News AI</title></source>
  </entry>
  <entry>
    <title>How to run Qwen3-Coder-Next 80b parameters model on 8Gb VRAM</title>
    <link href="https://www.reddit.com/r/LocalLLaMA/comments/1r5m4vl/how_to_run_qwen3codernext_80b_parameters_model_on/" rel="alternate" type="text/html"/>
    <id>https://www.reddit.com/r/LocalLLaMA/comments/1r5m4vl/how_to_run_qwen3codernext_80b_parameters_model_on/</id>
    <updated>2026-02-15T18:33:14.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[I am running large llms on my 8Gb laptop 3070ti. I have optimized: LTX-2, Wan2.2, HeartMula, ACE-STEP 1.5. And now i abble to run 80b parameters model Qwen3-Coder-Next !!! Instruction here: https://github.com/nalexand/Qwen3-Coder-OPTIMIZED It is FP8 quant 80Gb in size, it is…]]></summary>
    <source><title>r/LocalLLaMA</title></source>
  </entry>
  <entry>
    <title>Bad Apple but it&apos;s GPT-2 XL Attention Maps</title>
    <link href="https://www.reddit.com/r/LocalLLaMA/comments/1r5lra1/bad_apple_but_its_gpt2_xl_attention_maps/" rel="alternate" type="text/html"/>
    <id>https://www.reddit.com/r/LocalLLaMA/comments/1r5lra1/bad_apple_but_its_gpt2_xl_attention_maps/</id>
    <updated>2026-02-15T18:19:02.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[I optimized learnable input embeddings for a frozen GPT-2 XL model so that its attention maps display the frames of the Bad Apple music video. The model never saw an image in its life, The optimizer just found the right inputs. This is a silly little project but I found it…]]></summary>
    <source><title>r/LocalLLaMA</title></source>
  </entry>
  <entry>
    <title>8 Best Generative Engine Optimisation (GEO) Agencies in Australia for 2026 - Talons Marketing</title>
    <link href="https://talonsmarketing.com.au/8-best-generative-engine-optimisation-geo-agencies-australia/" rel="alternate" type="text/html"/>
    <id>https://talonsmarketing.com.au/8-best-generative-engine-optimisation-geo-agencies-australia/</id>
    <updated>2026-02-28T08:03:12.184Z</updated>
    <category term="industry-business" label="Industry &amp; Business"/>
    <summary type="html"><![CDATA[Aligning local SEO signals with generative search results · Their GEO strategy is particularly strong for local businesses, service providers, and multi-location brands that need to appear in AI answers like “best provider near me” or “recommended service in Melbourne.”]]></summary>
    <source><title>Brave Search</title></source>
  </entry>
  <entry>
    <title>If you were starting with local LLMs today, what would you do differently</title>
    <link href="https://www.reddit.com/r/LocalLLaMA/comments/1r5k46x/if_you_were_starting_with_local_llms_today_what/" rel="alternate" type="text/html"/>
    <id>https://www.reddit.com/r/LocalLLaMA/comments/1r5k46x/if_you_were_starting_with_local_llms_today_what/</id>
    <updated>2026-02-15T17:15:44.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[Hey all, I am seriously considering investing a significant portion of my signing bonus into a local LLM setup as a hobby and learning project once I start my job in August. I am currently in university. I have studied a lot of theory, but I feel I am missing practical, hands-on…]]></summary>
    <source><title>r/LocalLLaMA</title></source>
  </entry>
  <entry>
    <title>@unknown: @ExpressTechie Nice move by Anthropic. Use the new Claude free features for low-...</title>
    <link href="https://x.com/unknown/status/2022219269212131810" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022219269212131810</id>
    <updated>2026-02-13T08:00:19.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[@ExpressTechie Nice move by Anthropic. Use the new Claude free features for low-risk tasks, keep premium models for critical paths. Routing makes that split clean. Gatewayz lets you switch per request without rewrites.]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>@unknown: @GytisT @pcstyle53 @windsurf @OpenAI he says was fixed earlier today and sorry, ...</title>
    <link href="https://x.com/unknown/status/2022219053004394739" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022219053004394739</id>
    <updated>2026-02-13T07:59:27.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[@GytisT @pcstyle53 @windsurf @OpenAI he says was fixed earlier today and sorry, please do send other bugs (if a lot feel free to compile a gdoc) https://t.co/VVGkJBqkx7]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>@unknown: 記錄一下：
claudian配置antigravity tools 產生的api
ANTHROPIC_AUTH_TOKEN=sk-xxx
ANTHROPIC_A...</title>
    <link href="https://x.com/unknown/status/2022217932546396520" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022217932546396520</id>
    <updated>2026-02-13T07:55:00.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[記錄一下：
claudian配置antigravity tools 產生的api
ANTHROPIC_AUTH_TOKEN=sk-xxx
ANTHROPIC_API_KEY=""
ANTHROPIC_BASE_URL=http://localhost:8045
ANTHROPIC_DEFAULT_OPUS_MODEL=claude-opus-4-6-thinking

接入完成。
不知道用第三方antigravity tools，會不會被Google懲罰！ https://t.co/tCE02hJT0Z]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>@unknown: @GergelyOrosz @simonw @grinich @WorkOS @bcantrill michael at aie: https://t.co/U...</title>
    <link href="https://x.com/unknown/status/2022217788337828283" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022217788337828283</id>
    <updated>2026-02-13T07:54:26.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[@GergelyOrosz @simonw @grinich @WorkOS @bcantrill michael at aie: https://t.co/UPiHushX1I

we need to give a bigger update at WF this year]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>@unknown: I find @grok is meaningfully worse then ChatGPT and Gemini for most things...</title>
    <link href="https://x.com/unknown/status/2022214040236568891" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022214040236568891</id>
    <updated>2026-02-13T07:39:32.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[I find @grok is meaningfully worse then ChatGPT and Gemini for most things]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>@unknown: had a lovely @GergelyOrosz dinner with fellow tech writers and I found myself pa...</title>
    <link href="https://x.com/unknown/status/2022193296819597671" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022193296819597671</id>
    <updated>2026-02-13T06:17:07.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[had a lovely @GergelyOrosz dinner with fellow tech writers and I found myself passionately recommending @simonw some underrated talks,

You should watch:
- @grinich’s founding thesis for @WorkOS 
- @bcantrill’s talk on picking tech based on values they espouse

finding and…]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>@unknown: A schizophrenic cult has emerged around ChatGPT 4o, and the psychosis will only ...</title>
    <link href="https://x.com/unknown/status/2022188079377957000" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022188079377957000</id>
    <updated>2026-02-13T05:56:23.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[A schizophrenic cult has emerged around ChatGPT 4o, and the psychosis will only get worse]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>@unknown: I guarantee if you catch this woman off guard and ask her who Hobbes was, you wi...</title>
    <link href="https://x.com/unknown/status/2022181866133237966" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022181866133237966</id>
    <updated>2026-02-13T05:31:41.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[I guarantee if you catch this woman off guard and ask her who Hobbes was, you will be met with the blankest emptiest expression ever
Even worse than the one she has on her face in this chatgpt-fueled video.]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>[R] Has anyone experimented with MHC on traditional autoencoders/convolutional architectures?</title>
    <link href="https://www.reddit.com/r/MachineLearning/comments/1r3gqng/r_has_anyone_experimented_with_mhc_on_traditional/" rel="alternate" type="text/html"/>
    <id>https://www.reddit.com/r/MachineLearning/comments/1r3gqng/r_has_anyone_experimented_with_mhc_on_traditional/</id>
    <updated>2026-02-13T05:27:06.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[I'm currently making a baseline autoencoder for this super freaking huge hyperspectral image dataset I have. It's a really big pain to work with and to get decent results, and I had to basically pull all stops including using ResNeXt2, channel-by-channel processing and grouping,…]]></summary>
    <source><title>r/MachineLearning</title></source>
  </entry>
  <entry>
    <title>@unknown: Stop hiring executors and start training supervisors. AI shouldn’t just speed up...</title>
    <link href="https://x.com/unknown/status/2022175312675823649" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022175312675823649</id>
    <updated>2026-02-13T05:05:39.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[Stop hiring executors and start training supervisors. AI shouldn’t just speed up broken processes; it should handle the routine while your people manage the complex. Shift to Human-over-the-loop and turn your team into an elite supervisory layer.

https://t.co/ViCi4srrdz…]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>Assessing LLM Reliability on Temporally Recent Open-Domain Questions</title>
    <link href="https://arxiv.org/abs/2602.11165" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11165</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11165v1 Announce Type: new Abstract: Large Language Models (LLMs) are increasingly deployed for open-domain question answering, yet their alignment with human perspectives on temporally recent information remains underexplored. We introduce RECOM (Reddit Evaluation…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>Latent Generative Solvers for Generalizable Long-Term Physics Simulation</title>
    <link href="https://arxiv.org/abs/2602.11229" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11229</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11229v1 Announce Type: new Abstract: We study long-horizon surrogate simulation across heterogeneous PDE systems. We introduce Latent Generative Solvers (LGS), a two-stage framework that (i) maps diverse PDE states into a shared latent physics space with a pretrained…]]></summary>
    <source><title>arXiv cs.AI</title></source>
  </entry>
  <entry>
    <title>Bi-Level Prompt Optimization for Multimodal LLM-as-a-Judge</title>
    <link href="https://arxiv.org/abs/2602.11340" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11340</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11340v1 Announce Type: new Abstract: Large language models (LLMs) have become widely adopted as automated judges for evaluating AI-generated content. Despite their success, aligning LLM-based evaluations with human judgments remains challenging. While supervised…]]></summary>
    <source><title>arXiv cs.AI</title></source>
  </entry>
  <entry>
    <title>AgentNoiseBench: Benchmarking Robustness of Tool-Using LLM Agents Under Noisy Condition</title>
    <link href="https://arxiv.org/abs/2602.11348" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11348</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11348v1 Announce Type: new Abstract: Recent advances in large language models have enabled LLM-based agents to achieve strong performance on a variety of benchmarks. However, their performance in real-world deployments often that observed on benchmark settings,…]]></summary>
    <source><title>arXiv cs.AI</title></source>
  </entry>
  <entry>
    <title>Pushing Forward Pareto Frontiers of Proactive Agents with Behavioral Agentic Optimization</title>
    <link href="https://arxiv.org/abs/2602.11351" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11351</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11351v1 Announce Type: new Abstract: Proactive large language model (LLM) agents aim to actively plan, query, and interact over multiple turns, enabling efficient task completion beyond passive instruction following and making them essential for real-world,…]]></summary>
    <source><title>arXiv cs.AI</title></source>
  </entry>
  <entry>
    <title>Response-Based Knowledge Distillation for Multilingual Jailbreak Prevention Unwittingly Compromises Safety</title>
    <link href="https://arxiv.org/abs/2602.11157" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11157</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11157v1 Announce Type: new Abstract: Large language models (LLMs) are increasingly deployed worldwide, yet their safety alignment remains predominantly English-centric. This allows for vulnerabilities in non-English contexts, especially with low-resource languages. We…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>Visualizing and Benchmarking LLM Factual Hallucination Tendencies via Internal State Analysis and Clustering</title>
    <link href="https://arxiv.org/abs/2602.11167" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11167</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11167v1 Announce Type: new Abstract: Large Language Models (LLMs) often hallucinate, generating nonsensical or false information that can be especially harmful in sensitive fields such as medicine or law. To study this phenomenon systematically, we introduce…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>Explaining AI Without Code: A User Study on Explainable AI</title>
    <link href="https://arxiv.org/abs/2602.11159" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11159</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11159v1 Announce Type: new Abstract: The increasing use of Machine Learning (ML) in sensitive domains such as healthcare, finance, and public policy has raised concerns about the transparency of automated decisions. Explainable AI (XAI) addresses this by clarifying…]]></summary>
    <source><title>arXiv cs.AI</title></source>
  </entry>
  <entry>
    <title>Dissecting Subjectivity and the &quot;Ground Truth&quot; Illusion in Data Annotation</title>
    <link href="https://arxiv.org/abs/2602.11318" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11318</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11318v1 Announce Type: new Abstract: In machine learning, "ground truth" refers to the assumed correct labels used to train and evaluate models. However, the foundational "ground truth" paradigm rests on a positivistic fallacy that treats human disagreement as…]]></summary>
    <source><title>arXiv cs.AI</title></source>
  </entry>
  <entry>
    <title>TRACER: Trajectory Risk Aggregation for Critical Episodes in Agentic Reasoning</title>
    <link href="https://arxiv.org/abs/2602.11409" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11409</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11409v1 Announce Type: new Abstract: Estimating uncertainty for AI agents in real-world multi-turn tool-using interaction with humans is difficult because failures are often triggered by sparse critical episodes (e.g., looping, incoherent tool use, or user-agent…]]></summary>
    <source><title>arXiv cs.AI</title></source>
  </entry>
  <entry>
    <title>Distributionally Robust Cooperative Multi-Agent Reinforcement Learning via Robust Value Factorization</title>
    <link href="https://arxiv.org/abs/2602.11437" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11437</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11437v1 Announce Type: new Abstract: Cooperative multi-agent reinforcement learning (MARL) commonly adopts centralized training with decentralized execution, where value-factorization methods enforce the individual-global-maximum (IGM) principle so that decentralized…]]></summary>
    <source><title>arXiv cs.AI</title></source>
  </entry>
  <entry>
    <title>Credit Where It is Due: Cross-Modality Connectivity Drives Precise Reinforcement Learning for MLLM Reasoning</title>
    <link href="https://arxiv.org/abs/2602.11455" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11455</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="image-video-generation" label="Image &amp; Video Generation"/>
    <summary type="html"><![CDATA[arXiv:2602.11455v1 Announce Type: new Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has significantly advanced the reasoning capabilities of Multimodal Large Language Models (MLLMs), yet how visual evidence is integrated during reasoning remains poorly…]]></summary>
    <source><title>arXiv cs.AI</title></source>
  </entry>
  <entry>
    <title>Retrieval Heads are Dynamic</title>
    <link href="https://arxiv.org/abs/2602.11162" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11162</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11162v1 Announce Type: new Abstract: Recent studies have identified "retrieval heads" in Large Language Models (LLMs) responsible for extracting information from input contexts. However, prior works largely rely on static statistics aggregated across datasets,…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>Small Updates, Big Doubts: Does Parameter-Efficient Fine-tuning Enhance Hallucination Detection ?</title>
    <link href="https://arxiv.org/abs/2602.11166" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11166</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11166v1 Announce Type: new Abstract: Parameter-efficient fine-tuning (PEFT) methods are widely used to adapt large language models (LLMs) to downstream tasks and are often assumed to improve factual correctness. However, how the parameter-efficient fine-tuning methods…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>Enhancing SDG-Text Classification with Combinatorial Fusion Analysis and Generative AI</title>
    <link href="https://arxiv.org/abs/2602.11168" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11168</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11168v1 Announce Type: new Abstract: (Natural Language Processing) NLP techniques such as text classification and topic discovery are very useful in many application areas including information retrieval, knowledge discovery, policy formulation, and decision-making.…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>Disentangling Direction and Magnitude in Transformer Representations: A Double Dissociation Through L2-Matched Perturbation Analysis</title>
    <link href="https://arxiv.org/abs/2602.11169" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11169</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11169v1 Announce Type: new Abstract: Transformer hidden states encode information as high-dimensional vectors, yet whether direction (orientation in representational space) and magnitude (vector norm) serve distinct functional roles remains unclear. Studying…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>PRIME: Policy-Reinforced Iterative Multi-agent Execution for Algorithmic Reasoning in Large Language Models</title>
    <link href="https://arxiv.org/abs/2602.11170" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11170</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11170v1 Announce Type: new Abstract: Large language models have demonstrated remarkable capabilities across diverse reasoning tasks, yet their performance on algorithmic reasoning remains limited. To handle this limitation, we propose PRIME (Policy-Reinforced…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>Efficient Hyper-Parameter Search for LoRA via Language-aided Bayesian Optimization</title>
    <link href="https://arxiv.org/abs/2602.11171" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11171</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11171v1 Announce Type: new Abstract: Fine-tuning Large Language Models (LLMs) with Low-Rank Adaptation (LoRA) enables resource-efficient personalization or specialization, but it comes at the expense of additional hyperparameter tuning. Although LoRA makes fine-tuning…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>Synthesizing the Virtual Advocate: A Multi-Persona Speech Generation Framework for Diverse Linguistic Jurisdictions in Indic Languages</title>
    <link href="https://arxiv.org/abs/2602.11172" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11172</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="voice-audio" label="Voice &amp; Audio"/>
    <summary type="html"><![CDATA[arXiv:2602.11172v1 Announce Type: new Abstract: Legal advocacy requires a unique combination of authoritative tone, rhythmic pausing for emphasis, and emotional intelligence. This study investigates the performance of the Gemini 2.5 Flash TTS and Gemini 2.5 Pro TTS models in…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>Barriers to Discrete Reasoning with Transformers: A Survey Across Depth, Exactness, and Bandwidth</title>
    <link href="https://arxiv.org/abs/2602.11175" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11175</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11175v1 Announce Type: new Abstract: Transformers have become the foundational architecture for a broad spectrum of sequence modeling applications, underpinning state-of-the-art systems in natural language processing, vision, and beyond. However, their theoretical…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>Voxtral Realtime</title>
    <link href="https://arxiv.org/abs/2602.11298" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11298</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="voice-audio" label="Voice &amp; Audio"/>
    <summary type="html"><![CDATA[arXiv:2602.11298v1 Announce Type: new Abstract: We introduce Voxtral Realtime, a natively streaming automatic speech recognition model that matches offline transcription quality at sub-second latency. Unlike approaches that adapt offline models through chunking or sliding…]]></summary>
    <source><title>arXiv cs.AI</title></source>
  </entry>
  <entry>
    <title>GHOST: Unmasking Phantom States in Mamba2 via Grouped Hidden-state Output-aware Selection &amp; Truncation</title>
    <link href="https://arxiv.org/abs/2602.11408" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11408</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11408v1 Announce Type: new Abstract: While Mamba2's expanded state dimension enhances temporal modeling, it incurs substantial inference overhead that saturates bandwidth during autoregressive generation. Standard pruning methods fail to address this bottleneck:…]]></summary>
    <source><title>arXiv cs.AI</title></source>
  </entry>
  <entry>
    <title>HybridRAG: A Practical LLM-based ChatBot Framework based on Pre-Generated Q&amp;A over Raw Unstructured Documents</title>
    <link href="https://arxiv.org/abs/2602.11156" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11156</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11156v1 Announce Type: new Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful approach for grounding Large Language Model (LLM)-based chatbot responses on external knowledge. However, existing RAG studies typically assume well-structured textual…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>Nested Named Entity Recognition in Plasma Physics Research Articles</title>
    <link href="https://arxiv.org/abs/2602.11163" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11163</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11163v1 Announce Type: new Abstract: Named Entity Recognition (NER) is an important task in natural language processing that aims to identify and extract key entities from unstructured text. We present a novel application of NER in plasma physics research articles and…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>Author-in-the-Loop Response Generation and Evaluation: Integrating Author Expertise and Intent in Responses to Peer Review</title>
    <link href="https://arxiv.org/abs/2602.11173" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11173</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11173v1 Announce Type: new Abstract: Author response (rebuttal) writing is a critical stage of scientific peer review that demands substantial author effort. Recent work frames this task as automatic text generation, underusing author expertise and intent. In…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>The Script Tax: Measuring Tokenization-Driven Efficiency and Latency Disparities in Multilingual Language Models</title>
    <link href="https://arxiv.org/abs/2602.11174" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11174</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11174v1 Announce Type: new Abstract: Pretrained multilingual language models are often assumed to be script-agnostic, yet their tokenizers can impose systematic costs on certain writing systems. We quantify this script tax by comparing two orthographic variants with…]]></summary>
    <source><title>arXiv cs.CL</title></source>
  </entry>
  <entry>
    <title>GAC-KAN: An Ultra-Lightweight GNSS Interference Classifier for GenAI-Powered Consumer Edge Devices</title>
    <link href="https://arxiv.org/abs/2602.11186" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11186</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11186v1 Announce Type: new Abstract: The integration of Generative AI (GenAI) into Consumer Electronics (CE)--from AI-powered assistants in wearables to generative planning in autonomous Uncrewed Aerial Vehicles (UAVs)--has revolutionized user experiences. However,…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>Automated Optimization Modeling via a Localizable Error-Driven Perspective</title>
    <link href="https://arxiv.org/abs/2602.11164" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11164</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11164v1 Announce Type: new Abstract: Automated optimization modeling via Large Language Models (LLMs) has emerged as a promising approach to assist complex human decision-making. While post-training has become a pivotal technique to enhance LLMs' capabilities in this…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>KBVQ-MoE: KLT-guided SVD with Bias-Corrected Vector Quantization for MoE Large Language Models</title>
    <link href="https://arxiv.org/abs/2602.11184" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11184</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11184v1 Announce Type: new Abstract: Mixture of Experts (MoE) models have achieved great success by significantly improving performance while maintaining computational efficiency through sparse expert activation. However, their enormous parameter sizes and memory…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>Spectra: Rethinking Optimizers for LLMs Under Spectral Anisotropy</title>
    <link href="https://arxiv.org/abs/2602.11185" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11185</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11185v1 Announce Type: new Abstract: Gradient signals in LLM training are highly anisotropic: recurrent linguistic structure concentrates energy into a small set of dominant spectral directions, while context specific information resides in a long tail. We show that…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>Predicting the post-wildfire mudflow onset using machine learning models on multi-parameter experimental data</title>
    <link href="https://arxiv.org/abs/2602.11194" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11194</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11194v1 Announce Type: new Abstract: Post-wildfire mudflows are increasingly hazardous due to the prevalence of wildfires, including those on the wildland-urban interface. Upon burning, soil on the surface or immediately beneath becomes hydrophobic, a phenomenon that…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>Charting Empirical Laws for LLM Fine-Tuning in Scientific Multi-Discipline Learning</title>
    <link href="https://arxiv.org/abs/2602.11215" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11215</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11215v1 Announce Type: new Abstract: While large language models (LLMs) have achieved strong performance through fine-tuning within individual scientific domains, their learning dynamics in multi-disciplinary contexts remains poorly understood, despite the promise of…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>TDPNavigator-Placer: Thermal- and Wirelength-Aware Chiplet Placement in 2.5D Systems Through Multi-Agent Reinforcement Learning</title>
    <link href="https://arxiv.org/abs/2602.11187" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11187</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11187v1 Announce Type: new Abstract: The rapid growth of electronics has accelerated the adoption of 2.5D integrated circuits, where effective automated chiplet placement is essential as systems scale to larger and more heterogeneous chiplet assemblies. Existing…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>Time-TK: A Multi-Offset Temporal Interaction Framework Combining Transformer and Kolmogorov-Arnold Networks for Time Series Forecasting</title>
    <link href="https://arxiv.org/abs/2602.11190" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11190</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11190v1 Announce Type: new Abstract: Time series forecasting is crucial for the World Wide Web and represents a core technical challenge in ensuring the stable and efficient operation of modern web services, such as intelligent transportation and website throughput.…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>MELINOE: Fine-Tuning Enables Memory-Efficient Inference for Mixture-of-Experts Models</title>
    <link href="https://arxiv.org/abs/2602.11192" rel="alternate" type="text/html"/>
    <id>https://arxiv.org/abs/2602.11192</id>
    <updated>2026-02-13T05:00:00.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[arXiv:2602.11192v1 Announce Type: new Abstract: Mixture-of-Experts (MoE) model architectures can significantly reduce the number of activated parameters per token, enabling computationally efficient training and inference. However, their large overall parameter counts and model…]]></summary>
    <source><title>arXiv cs.LG</title></source>
  </entry>
  <entry>
    <title>@unknown: To give credit to the economists, these two papers from early 2023 (by @danielro...</title>
    <link href="https://x.com/unknown/status/2022160521366319297" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022160521366319297</id>
    <updated>2026-02-13T04:06:52.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[To give credit to the economists, these two papers from early 2023 (by @danielrock, @robseamans and others who I am not sure are still on X) did a great job forecasting which jobs would turn out to be most exposed to AI using O*NET, and they were written during the GPT-3.5 era.…]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>@unknown: I’m impressed both by the quality of the pelican and that “SVG of a pelican ridi...</title>
    <link href="https://x.com/unknown/status/2022143097841627295" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022143097841627295</id>
    <updated>2026-02-13T02:57:38.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[I’m impressed both by the quality of the pelican and that “SVG of a pelican riding a bicycle” remains an unsaturated benchmark — surprisingly high ceiling on this task]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>@unknown: @hooyahdeepsea69 @newstart_2024 Galloway&apos;s pod clip nails AI&apos;s hype vs. reality—...</title>
    <link href="https://x.com/unknown/status/2022142481488355472" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022142481488355472</id>
    <updated>2026-02-13T02:55:11.000Z</updated>
    <category term="strategy-opinion" label="Strategy &amp; Opinion"/>
    <summary type="html"><![CDATA[@hooyahdeepsea69 @newstart_2024 Galloway's pod clip nails AI's hype vs. reality—job displacement, quality dips for cost cuts, welfare strains. In abundance era, this risks Mouse Utopia's decay without ethical AI blueprints for fair automation. How'd you blueprint safeguards…]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>@unknown: I am surprised that we don’t see more governments and non-profits going all-in o...</title>
    <link href="https://x.com/unknown/status/2022130014712741900" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022130014712741900</id>
    <updated>2026-02-13T02:05:39.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[I am surprised that we don’t see more governments and non-profits going all-in on transformational AI use cases for good. There are areas like journalism &amp; education where funding ambitious, civic-minded &amp; context-sensitive moonshots could make a difference and empower…]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>@unknown: Rather than converting everything into random benchmark numbers that humans have...</title>
    <link href="https://x.com/unknown/status/2022118940168831302" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022118940168831302</id>
    <updated>2026-02-13T01:21:39.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[Rather than converting everything into random benchmark numbers that humans have no comparisons for, we should just use D&amp;D stat blocks for AI (CHR, INT, WIS) and robots (STR, DEX, CON). You then can do reasonable comparisons like whether any given AI can outsmart a beholder.]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>@unknown: The differentiation between long running agents and in-the-moment agents, that p...</title>
    <link href="https://x.com/unknown/status/2022106144622408182" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022106144622408182</id>
    <updated>2026-02-13T00:30:48.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[The differentiation between long running agents and in-the-moment agents, that preform a realtime assistant - is a big deal. 
It will integrate into  development habits quickly while long running agents works isolated 
Love it 

https://t.co/OiU3uBUmDr]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>@unknown: AI is moving so fast that we’re all living in ambiguity: hype vs reality.
What w...</title>
    <link href="https://x.com/unknown/status/2022103474075533496" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022103474075533496</id>
    <updated>2026-02-13T00:20:11.000Z</updated>
    <category term="strategy-opinion" label="Strategy &amp; Opinion"/>
    <summary type="html"><![CDATA[AI is moving so fast that we’re all living in ambiguity: hype vs reality.
What will be the safest job in terms of next 5 years?]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>@unknown: AI video isn’t a feature race anymore — it’s a market war.

Who’s actually winni...</title>
    <link href="https://x.com/unknown/status/2022098644510384294" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022098644510384294</id>
    <updated>2026-02-13T00:01:00.000Z</updated>
    <category term="image-video-generation" label="Image &amp; Video Generation"/>
    <summary type="html"><![CDATA[AI video isn’t a feature race anymore — it’s a market war.

Who’s actually winning on users, downloads, and daily active engagement in 2026?

- #Seedance 2.0. 
- #Sora 2. 
- #Kling 3.0. 
- #Runway Gen-4.5.

The real story isn’t quality — it’s scale. 👇
https://t.co/96czeA56TJ]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>Amid disappointing earnings, Pinterest claims it sees more searches than ChatGPT</title>
    <link href="https://techcrunch.com/2026/02/12/amid-disappointing-earnings-pinterest-claims-it-sees-more-searches-than-chatgpt/" rel="alternate" type="text/html"/>
    <id>https://techcrunch.com/2026/02/12/amid-disappointing-earnings-pinterest-claims-it-sees-more-searches-than-chatgpt/</id>
    <updated>2026-02-12T23:26:56.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[Pinterest's stock tumbles after an earnings miss, with higher-than-expected usage its only bright spot.]]></summary>
    <source><title>TechCrunch AI</title></source>
  </entry>
  <entry>
    <title>IBM will hire your entry-level talent in the age of AI</title>
    <link href="https://techcrunch.com/2026/02/12/ibm-will-hire-your-entry-level-talent-in-the-age-of-ai/" rel="alternate" type="text/html"/>
    <id>https://techcrunch.com/2026/02/12/ibm-will-hire-your-entry-level-talent-in-the-age-of-ai/</id>
    <updated>2026-02-12T23:23:17.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[IBM plans to triple its entry-level hiring in the U.S. in 2026, but these jobs will have different tasks than in previous years.]]></summary>
    <source><title>TechCrunch AI</title></source>
  </entry>
  <entry>
    <title>OpenAI sidesteps Nvidia with unusually fast coding model on plate-sized chips</title>
    <link href="https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/" rel="alternate" type="text/html"/>
    <id>https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/</id>
    <updated>2026-02-12T22:56:02.000Z</updated>
    <category term="ai-coding-agents" label="AI Coding &amp; Agents"/>
    <summary type="html"><![CDATA[OpenAI's new GPT‑5.3‑Codex‑Spark is 15 times faster at coding than its predecessor.]]></summary>
    <source><title>Ars Technica AI</title></source>
  </entry>
  <entry>
    <title>[P] ML training cluster for university students</title>
    <link href="https://www.reddit.com/r/MachineLearning/comments/1r388tr/p_ml_training_cluster_for_university_students/" rel="alternate" type="text/html"/>
    <id>https://www.reddit.com/r/MachineLearning/comments/1r388tr/p_ml_training_cluster_for_university_students/</id>
    <updated>2026-02-12T22:55:04.000Z</updated>
    <category term="research-papers" label="Research &amp; Papers"/>
    <summary type="html"><![CDATA[Hi! I'm an exec at a University AI research club. We are trying to build a gpu cluster for our student body so they can have reliable access to compute, but we aren't sure where to start. Our goal is to have a cluster that can be improved later on - i.e. expand it with more…]]></summary>
    <source><title>r/MachineLearning</title></source>
  </entry>
  <entry>
    <title>The Evolution of Categorization During the era of AI Programming [D]</title>
    <link href="https://www.reddit.com/r/MachineLearning/comments/1r383nr/the_evolution_of_categorization_during_the_era_of/" rel="alternate" type="text/html"/>
    <id>https://www.reddit.com/r/MachineLearning/comments/1r383nr/the_evolution_of_categorization_during_the_era_of/</id>
    <updated>2026-02-12T22:49:21.000Z</updated>
    <category term="industry-business" label="Industry &amp; Business"/>
    <summary type="html"><![CDATA[TL;DR - Hypothetically If the majority of code written is eventually generative, does this mean that the field of categorization will stagnate? If yes, does this have real implications; what if the future bottle neck isn't the AI or its capabilities, but antiquated ways in which…]]></summary>
    <source><title>r/MachineLearning</title></source>
  </entry>
  <entry>
    <title>[D] Conformal Prediction vs naive thresholding to represent uncertainty</title>
    <link href="https://www.reddit.com/r/MachineLearning/comments/1r37m2f/d_conformal_prediction_vs_naive_thresholding_to/" rel="alternate" type="text/html"/>
    <id>https://www.reddit.com/r/MachineLearning/comments/1r37m2f/d_conformal_prediction_vs_naive_thresholding_to/</id>
    <updated>2026-02-12T22:29:39.000Z</updated>
    <category term="strategy-opinion" label="Strategy &amp; Opinion"/>
    <summary type="html"><![CDATA[So I recently found out about conformal prediction (cp). I’m still trying to understand it and implications of it for tasks like classification/anomaly detection. Say we have a knn based anomaly detector trained on non anomalous samples. I’m wondering how using something…]]></summary>
    <source><title>r/MachineLearning</title></source>
  </entry>
  <entry>
    <title>‘Uncanny Valley’: ICE’s Secret Expansion Plans, Palantir Workers’ Ethical Concerns, and AI Assistants</title>
    <link href="https://www.wired.com/story/uncanny-valley-podcast-ice-expansion-palantir-workers-ethical-concerns-openclaw-ai-assistants/" rel="alternate" type="text/html"/>
    <id>https://www.wired.com/story/uncanny-valley-podcast-ice-expansion-palantir-workers-ethical-concerns-openclaw-ai-assistants/</id>
    <updated>2026-02-12T22:12:42.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[In this episode of Uncanny Valley, our hosts dive into WIRED’s scoop about a secret Trump administration campaign extending right into your backyard.]]></summary>
    <source><title>Wired AI</title></source>
  </entry>
  <entry>
    <title>Musk needed a new vision for SpaceX and xAI. He landed on Moonbase Alpha.</title>
    <link href="https://techcrunch.com/2026/02/12/musk-needed-a-new-vision-for-spacex-and-xai-he-landed-on-moonbase-alpha/" rel="alternate" type="text/html"/>
    <id>https://techcrunch.com/2026/02/12/musk-needed-a-new-vision-for-spacex-and-xai-he-landed-on-moonbase-alpha/</id>
    <updated>2026-02-12T22:10:55.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA["I really want to see a mass driver on the moon that is shooting AI satellites into deep space."]]></summary>
    <source><title>TechCrunch AI</title></source>
  </entry>
  <entry>
    <title>Owning the AI Pareto Frontier — Jeff Dean</title>
    <link href="https://www.latent.space/p/jeffdean" rel="alternate" type="text/html"/>
    <id>https://www.latent.space/p/jeffdean</id>
    <updated>2026-02-12T22:02:35.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[From rewriting Google&#8217;s search stack in the early 2000s to reviving sparse trillion-parameter models and co-designing TPUs with frontier ML research, Jeff Dean has quietly shaped nearly every layer of the modern AI stack.]]></summary>
    <source><title>Latent Space</title></source>
  </entry>
  <entry>
    <title>@unknown: Microsoft Agent Framework: Exposing an Existing AI Agent as an MCP Tool https://...</title>
    <link href="https://x.com/unknown/status/2022058956634698002" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022058956634698002</id>
    <updated>2026-02-12T21:23:17.000Z</updated>
    <category term="ai-tools-platforms" label="AI Tools &amp; Platforms"/>
    <summary type="html"><![CDATA[Microsoft Agent Framework: Exposing an Existing AI Agent as an MCP Tool https://t.co/UncLCUq7WG #machinelearning #ai]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
  <entry>
    <title>@unknown: The model is faster, the pelican isn&apos;t as good!

GPT-5.3 Codex Spark on the left...</title>
    <link href="https://x.com/unknown/status/2022057896121708735" rel="alternate" type="text/html"/>
    <id>https://x.com/unknown/status/2022057896121708735</id>
    <updated>2026-02-12T21:19:05.000Z</updated>
    <category term="ai-coding-agents" label="AI Coding &amp; Agents"/>
    <summary type="html"><![CDATA[The model is faster, the pelican isn't as good!

GPT-5.3 Codex Spark on the left, GPT-5.3 Codex 5.3 on the right - both at medium quality settings https://t.co/d9ZxLjohT3]]></summary>
    <source><title>X/@unknown</title></source>
  </entry>
</feed>