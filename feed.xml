<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>Product Intelligence — GenAI Knowledge Base</title>
    <link>https://fr491l3b0t.github.io/kanban/genai-kb-editorial.html</link>
    <description>Curated daily intelligence on generative AI: tools, research, strategy, industry moves. 4,600+ entries from 41 RSS feeds, Reddit, X bookmarks, and Brave Search.</description>
    <language>en-AU</language>
    <copyright>© 2026 Raphael Ruz</copyright>
    <lastBuildDate>Sat, 28 Feb 2026 08:03:12 GMT</lastBuildDate>
    <generator>Product Intelligence KB Feed Builder</generator>
    <atom:link href="https://fr491l3b0t.github.io/kanban/feed.xml" rel="self" type="application/rss+xml" />
    <image>
      <url>https://fr491l3b0t.github.io/kanban/pi-icon.png</url>
      <title>Product Intelligence — GenAI Knowledge Base</title>
      <link>https://fr491l3b0t.github.io/kanban/genai-kb-editorial.html</link>
    </image>
    <item>
      <title>Google puts users at risk by downplaying health disclaimers under AI Overviews</title>
      <link>https://www.theguardian.com/technology/2026/feb/16/google-puts-users-at-risk-downplaying-disclaimers-ai-overviews</link>
      <description><![CDATA[Exclusive: Google fails to include safety warnings when users are first presented with AI-generated medical adviceGoogle is putting people at risk of harm by downplaying safety warnings that its AI-generated medical advice may be wrong.When answering queries about sensitive…]]></description>
      <pubDate>Mon, 16 Feb 2026 07:30:13 GMT</pubDate>
      <category>Ethics &amp; Regulation</category>
      <guid isPermaLink="true">https://www.theguardian.com/technology/2026/feb/16/google-puts-users-at-risk-downplaying-disclaimers-ai-overviews</guid>
      <source url="https://www.theguardian.com/technology/2026/feb/16/google-puts-users-at-risk-downplaying-disclaimers-ai-overviews">Guardian AI</source>
    </item>
    <item>
      <title>[D] “I Was Told There Would Be No Math” Why many ML projects fail before the model</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1r61vx9/d_i_was_told_there_would_be_no_math_why_many_ml/</link>
      <description><![CDATA[I have been doing machine learning for less than a year. My background is 25 years as a technical architect across financial services, healthcare, and education. I have worked on fixed income risk analytics, mortgage modeling using Monte Carlo simulation, Medicaid and Medicare…]]></description>
      <pubDate>Mon, 16 Feb 2026 06:12:42 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://www.reddit.com/r/MachineLearning/comments/1r61vx9/d_i_was_told_there_would_be_no_math_why_many_ml/</guid>
      <source url="https://www.reddit.com/r/MachineLearning/comments/1r61vx9/d_i_was_told_there_would_be_no_math_why_many_ml/">r/MachineLearning</source>
    </item>
    <item>
      <title>A Machine Learning Approach to the Nirenberg Problem</title>
      <link>https://arxiv.org/abs/2602.12368</link>
      <description><![CDATA[arXiv:2602.12368v1 Announce Type: new Abstract: This work introduces the Nirenberg Neural Network: a numerical approach to the Nirenberg problem of prescribing Gaussian curvature on $S^2$ for metrics that are pointwise conformal to the round metric. Our mesh-free…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12368</guid>
      <source url="https://arxiv.org/abs/2602.12368">arXiv cs.LG</source>
    </item>
    <item>
      <title>Synthetic Interaction Data for Scalable Personalization in Large Language Models</title>
      <link>https://arxiv.org/abs/2602.12394</link>
      <description><![CDATA[arXiv:2602.12394v1 Announce Type: new Abstract: Personalized prompting offers large opportunities for deploying large language models (LLMs) to diverse users, yet existing prompt optimization methods primarily focus on task-level optimization while largely overlooking…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12394</guid>
      <source url="https://arxiv.org/abs/2602.12394">arXiv cs.LG</source>
    </item>
    <item>
      <title>Intrinsic Credit Assignment for Long Horizon Interaction</title>
      <link>https://arxiv.org/abs/2602.12342</link>
      <description><![CDATA[arXiv:2602.12342v1 Announce Type: new Abstract: How can we train agents to navigate uncertainty over long horizons? In this work, we propose {\Delta}Belief-RL, which leverages a language model's own intrinsic beliefs to reward intermediate progress. Our method utilizes the…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12342</guid>
      <source url="https://arxiv.org/abs/2602.12342">arXiv cs.LG</source>
    </item>
    <item>
      <title>Value Bonuses using Ensemble Errors for Exploration in Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2602.12375</link>
      <description><![CDATA[arXiv:2602.12375v1 Announce Type: new Abstract: Optimistic value estimates provide one mechanism for directed exploration in reinforcement learning (RL). The agent acts greedily with respect to an estimate of the value plus what can be seen as a value bonus. The value bonus can…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12375</guid>
      <source url="https://arxiv.org/abs/2602.12375">arXiv cs.LG</source>
    </item>
    <item>
      <title>TFT-ACB-XML: Decision-Level Integration of Customized Temporal Fusion Transformer and Attention-BiLSTM with XGBoost Meta-Learner for BTC Price Forecasting</title>
      <link>https://arxiv.org/abs/2602.12380</link>
      <description><![CDATA[arXiv:2602.12380v1 Announce Type: new Abstract: Accurate forecasting of Bitcoin (BTC) has always been a challenge because decentralized markets are non-linear, highly volatile, and have temporal irregularities. Existing deep learning models often struggle with interpretability…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12380</guid>
      <source url="https://arxiv.org/abs/2602.12380">arXiv cs.LG</source>
    </item>
    <item>
      <title>Rational Neural Networks have Expressivity Advantages</title>
      <link>https://arxiv.org/abs/2602.12390</link>
      <description><![CDATA[arXiv:2602.12390v1 Announce Type: new Abstract: We study neural networks with trainable low-degree rational activation functions and show that they are more expressive and parameter-efficient than modern piecewise-linear and smooth activations such as ELU, LeakyReLU, LogSigmoid,…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12390</guid>
      <source url="https://arxiv.org/abs/2602.12390">arXiv cs.LG</source>
    </item>
    <item>
      <title>OptiML: An End-to-End Framework for Program Synthesis and CUDA Kernel Optimization</title>
      <link>https://arxiv.org/abs/2602.12305</link>
      <description><![CDATA[arXiv:2602.12305v1 Announce Type: new Abstract: Generating high-performance CUDA kernels remains challenging due to the need to navigate a combinatorial space of low-level transformations under noisy and expensive hardware feedback. Although large language models can synthesize…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12305</guid>
      <source url="https://arxiv.org/abs/2602.12305">arXiv cs.LG</source>
    </item>
    <item>
      <title>Abstractive Red-Teaming of Language Model Character</title>
      <link>https://arxiv.org/abs/2602.12318</link>
      <description><![CDATA[arXiv:2602.12318v1 Announce Type: new Abstract: We want language model assistants to conform to a character specification, which asserts how the model should act across diverse user interactions. While models typically follow these character specifications, they can occasionally…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12318</guid>
      <source url="https://arxiv.org/abs/2602.12318">arXiv cs.LG</source>
    </item>
    <item>
      <title>The Appeal and Reality of Recycling LoRAs with Adaptive Merging</title>
      <link>https://arxiv.org/abs/2602.12323</link>
      <description><![CDATA[arXiv:2602.12323v1 Announce Type: new Abstract: The widespread availability of fine-tuned LoRA modules for open pre-trained models has led to an interest in methods that can adaptively merge LoRAs to improve performance. These methods typically include some way of selecting…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12323</guid>
      <source url="https://arxiv.org/abs/2602.12323">arXiv cs.LG</source>
    </item>
    <item>
      <title>Policy4OOD: A Knowledge-Guided World Model for Policy Intervention Simulation against the Opioid Overdose Crisis</title>
      <link>https://arxiv.org/abs/2602.12373</link>
      <description><![CDATA[arXiv:2602.12373v1 Announce Type: new Abstract: The opioid epidemic remains one of the most severe public health crises in the United States, yet evaluating policy interventions before implementation is difficult: multiple policies interact within a dynamic system where…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12373</guid>
      <source url="https://arxiv.org/abs/2602.12373">arXiv cs.LG</source>
    </item>
    <item>
      <title>Deep Doubly Debiased Longitudinal Effect Estimation with ICE G-Computation</title>
      <link>https://arxiv.org/abs/2602.12379</link>
      <description><![CDATA[arXiv:2602.12379v1 Announce Type: new Abstract: Estimating longitudinal treatment effects is essential for sequential decision-making but is challenging due to treatment-confounder feedback. While Iterative Conditional Expectation (ICE) G-computation offers a principled…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12379</guid>
      <source url="https://arxiv.org/abs/2602.12379">arXiv cs.LG</source>
    </item>
    <item>
      <title>Why Deep Jacobian Spectra Separate: Depth-Induced Scaling and Singular-Vector Alignment</title>
      <link>https://arxiv.org/abs/2602.12384</link>
      <description><![CDATA[arXiv:2602.12384v1 Announce Type: new Abstract: Understanding why gradient-based training in deep networks exhibits strong implicit bias remains challenging, in part because tractable singular-value dynamics are typically available only for balanced deep linear models. We…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12384</guid>
      <source url="https://arxiv.org/abs/2602.12384">arXiv cs.LG</source>
    </item>
    <item>
      <title>High-dimensional Level Set Estimation with Trust Regions and Double Acquisition Functions</title>
      <link>https://arxiv.org/abs/2602.12391</link>
      <description><![CDATA[arXiv:2602.12391v1 Announce Type: new Abstract: Level set estimation (LSE) classifies whether an unknown function's value exceeds a specified threshold for given inputs, a fundamental problem in many real-world applications. In active learning settings with limited initial data,…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12391</guid>
      <source url="https://arxiv.org/abs/2602.12391">arXiv cs.LG</source>
    </item>
    <item>
      <title>AstRL: Analog and Mixed-Signal Circuit Synthesis with Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2602.12402</link>
      <description><![CDATA[arXiv:2602.12402v1 Announce Type: new Abstract: Analog and mixed-signal (AMS) integrated circuits (ICs) lie at the core of modern computing and communications systems. However, despite the continued rise in design complexity, advances in AMS automation remain limited. This…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12402</guid>
      <source url="https://arxiv.org/abs/2602.12402">arXiv cs.LG</source>
    </item>
    <item>
      <title>MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs</title>
      <link>https://arxiv.org/abs/2602.12705</link>
      <description><![CDATA[arXiv:2602.12705v1 Announce Type: new Abstract: We present MedXIAOHE, a medical vision-language foundation model designed to advance general-purpose medical understanding and reasoning in real-world clinical applications. MedXIAOHE achieves state-of-the-art performance across…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12705</guid>
      <source url="https://arxiv.org/abs/2602.12705">arXiv cs.CL</source>
    </item>
    <item>
      <title>ReFilter: Improving Robustness of Retrieval-Augmented Generation via Gated Filter</title>
      <link>https://arxiv.org/abs/2602.12709</link>
      <description><![CDATA[arXiv:2602.12709v1 Announce Type: new Abstract: Retrieval-augmented generation (RAG) has become a dominant paradigm for grounding large language models (LLMs) with external evidence in knowledge-intensive question answering. A core design choice is how to fuse retrieved samples…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12709</guid>
      <source url="https://arxiv.org/abs/2602.12709">arXiv cs.CL</source>
    </item>
    <item>
      <title>Evaluating Robustness of Reasoning Models on Parameterized Logical Problems</title>
      <link>https://arxiv.org/abs/2602.12665</link>
      <description><![CDATA[arXiv:2602.12665v1 Announce Type: new Abstract: Logic provides a controlled testbed for evaluating LLM-based reasoners, yet standard SAT-style benchmarks often conflate surface difficulty (length, wording, clause order) with the structural phenomena that actually determine…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12665</guid>
      <source url="https://arxiv.org/abs/2602.12665">arXiv cs.AI</source>
    </item>
    <item>
      <title>X-SYS: A Reference Architecture for Interactive Explanation Systems</title>
      <link>https://arxiv.org/abs/2602.12748</link>
      <description><![CDATA[arXiv:2602.12748v1 Announce Type: new Abstract: The explainable AI (XAI) research community has proposed numerous technical methods, yet deploying explainability as systems remains challenging: Interactive explanation systems require both suitable algorithms and system…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12748</guid>
      <source url="https://arxiv.org/abs/2602.12748">arXiv cs.AI</source>
    </item>
    <item>
      <title>Discovering Semantic Latent Structures in Psychological Scales: A Response-Free Pathway to Efficient Simplification</title>
      <link>https://arxiv.org/abs/2602.12575</link>
      <description><![CDATA[arXiv:2602.12575v1 Announce Type: new Abstract: Psychological scale refinement traditionally relies on response-based methods such as factor analysis, item response theory, and network psychometrics to optimize item composition. Although rigorous, these approaches require large…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12575</guid>
      <source url="https://arxiv.org/abs/2602.12575">arXiv cs.CL</source>
    </item>
    <item>
      <title>$\mathcal{X}$-KD: General Experiential Knowledge Distillation for Large Language Models</title>
      <link>https://arxiv.org/abs/2602.12674</link>
      <description><![CDATA[arXiv:2602.12674v1 Announce Type: new Abstract: Knowledge Distillation (KD) for Large Language Models (LLMs) has become increasingly important as models grow in size and complexity. While existing distillation approaches focus on imitating teacher behavior, they often overlook…]]></description>
      <pubDate>Mon, 16 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.12674</guid>
      <source url="https://arxiv.org/abs/2602.12674">arXiv cs.CL</source>
    </item>
    <item>
      <title>[D] METR TH1.1: “working_time” is wildly different across models. Quick breakdown + questions.</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1r60e9a/d_metr_th11_working_time_is_wildly_different/</link>
      <description><![CDATA[METR’s Time Horizon benchmark (TH1 / TH1.1) estimates how long a task (in human-expert minutes) a model can complete with 50% reliability. https://preview.redd.it/sow40w7ccsjg1.png?width=1200&format=png&auto=webp&s=ff50a3774cfdc16bc51beedb869f9affda901c9f Most people look at…]]></description>
      <pubDate>Mon, 16 Feb 2026 04:53:31 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://www.reddit.com/r/MachineLearning/comments/1r60e9a/d_metr_th11_working_time_is_wildly_different/</guid>
      <source url="https://www.reddit.com/r/MachineLearning/comments/1r60e9a/d_metr_th11_working_time_is_wildly_different/">r/MachineLearning</source>
    </item>
    <item>
      <title>As AI data centers hit power limits, Peak XV backs Indian startup C2i to fix the bottleneck</title>
      <link>https://techcrunch.com/2026/02/15/as-ai-data-centers-hit-power-limits-peak-xv-backs-indian-startup-c2i-to-fix-the-bottleneck/</link>
      <description><![CDATA[C2i has raised $15 million as it tests a grid-to-GPU approach to reducing power losses in AI data centers.]]></description>
      <pubDate>Mon, 16 Feb 2026 01:00:00 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://techcrunch.com/2026/02/15/as-ai-data-centers-hit-power-limits-peak-xv-backs-indian-startup-c2i-to-fix-the-bottleneck/</guid>
      <source url="https://techcrunch.com/2026/02/15/as-ai-data-centers-hit-power-limits-peak-xv-backs-indian-startup-c2i-to-fix-the-bottleneck/">TechCrunch AI</source>
    </item>
    <item>
      <title>Blackstone backs Neysa in up to $1.2B financing as India pushes to build domestic AI infrastructure</title>
      <link>https://techcrunch.com/2026/02/15/blackstone-backs-neysa-in-up-to-1-2b-financing-as-india-pushes-to-build-domestic-ai-compute/</link>
      <description><![CDATA[Neysa is targeting deployments of more than 20,000 GPUs over time as demand for local AI compute accelerates.]]></description>
      <pubDate>Mon, 16 Feb 2026 00:30:00 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://techcrunch.com/2026/02/15/blackstone-backs-neysa-in-up-to-1-2b-financing-as-india-pushes-to-build-domestic-ai-compute/</guid>
      <source url="https://techcrunch.com/2026/02/15/blackstone-backs-neysa-in-up-to-1-2b-financing-as-india-pushes-to-build-domestic-ai-compute/">TechCrunch AI</source>
    </item>
    <item>
      <title>Deflation: Cost to train A.I. models drops 40% per year - Karpathy</title>
      <link>https://www.reddit.com/r/LocalLLaMA/comments/1r5uhfu/deflation_cost_to_train_ai_models_drops_40_per/</link>
      <description><![CDATA[https://github.com/karpathy/nanochat/discussions/481 Quote: ..., each year the cost to train GPT-2 is falling to approximately 40% of the previous year. (I think this is an underestimate and that further improvements are still quite possible). The gains come from everywhere:…]]></description>
      <pubDate>Mon, 16 Feb 2026 00:11:13 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://www.reddit.com/r/LocalLLaMA/comments/1r5uhfu/deflation_cost_to_train_ai_models_drops_40_per/</guid>
      <source url="https://www.reddit.com/r/LocalLLaMA/comments/1r5uhfu/deflation_cost_to_train_ai_models_drops_40_per/">r/LocalLLaMA</source>
    </item>
    <item>
      <title>[D] Advice on sequential recommendations architectures</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1r5u24v/d_advice_on_sequential_recommendations/</link>
      <description><![CDATA[I've tried to use a Transformer decoder architecture to model a sequence of user actions. Unlike an item_id paradigm where each interaction is described by the id of the item the user interacted with, I need to express the interaction through a series of attributes. For example…]]></description>
      <pubDate>Sun, 15 Feb 2026 23:52:36 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://www.reddit.com/r/MachineLearning/comments/1r5u24v/d_advice_on_sequential_recommendations/</guid>
      <source url="https://www.reddit.com/r/MachineLearning/comments/1r5u24v/d_advice_on_sequential_recommendations/">r/MachineLearning</source>
    </item>
    <item>
      <title>Imandra CodeLogician: LLMs + Formal Methods</title>
      <link>https://arxiv.org/abs/2601.11840</link>
      <description><![CDATA[Comments]]></description>
      <pubDate>Sun, 15 Feb 2026 22:43:27 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2601.11840</guid>
      <source url="https://arxiv.org/abs/2601.11840">Lobsters AI</source>
    </item>
    <item>
      <title>Makers of AI chatbots that put children at risk face big fines or UK ban</title>
      <link>https://www.theguardian.com/technology/2026/feb/15/ai-chatbots-children-risk-fines-uk-ban</link>
      <description><![CDATA[Starmer to announce ‘crackdown on vile illegal content created by AI’ after scandal involving Elon Musk’s Grok toolMakers of AI chatbots that put children at risk will face massive fines or even see their services blocked in the UK under law changes to be announced by Keir…]]></description>
      <pubDate>Sun, 15 Feb 2026 22:30:34 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://www.theguardian.com/technology/2026/feb/15/ai-chatbots-children-risk-fines-uk-ban</guid>
      <source url="https://www.theguardian.com/technology/2026/feb/15/ai-chatbots-children-risk-fines-uk-ban">Guardian AI</source>
    </item>
    <item>
      <title>inclusionAI/Ling-2.5-1T · Hugging Face</title>
      <link>https://www.reddit.com/r/LocalLLaMA/comments/1r5qfb8/inclusionailing251t_hugging_face/</link>
      <description><![CDATA[another 1T model :) from inclusionAI: Ling-2.5-1T, Inclusive Intelligence, Instant Impact. Today, we launch Ling-2.5-1T and make it open source. Thinking models raise the ceiling of intelligence, while instant models expand its reach by balancing efficiency and…]]></description>
      <pubDate>Sun, 15 Feb 2026 21:20:54 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://www.reddit.com/r/LocalLLaMA/comments/1r5qfb8/inclusionailing251t_hugging_face/</guid>
      <source url="https://www.reddit.com/r/LocalLLaMA/comments/1r5qfb8/inclusionailing251t_hugging_face/">r/LocalLLaMA</source>
    </item>
    <item>
      <title>[P]ut a Neural Network in VCV Rack 2 and told it to make sounds that influence my emotion tracking module…</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1r5ogo5/put_a_neural_network_in_vcv_rack_2_and_told_it_to/</link>
      <description><![CDATA[It decided to blow out my right headphone to make me show fear Some Background: I’m working on integrating computer vision and facial tracking into VCV Rack 2 with the goal of, for now, having emotions converted to CV output and granting control over synths. I’ve been adding a…]]></description>
      <pubDate>Sun, 15 Feb 2026 20:03:24 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://www.reddit.com/r/MachineLearning/comments/1r5ogo5/put_a_neural_network_in_vcv_rack_2_and_told_it_to/</guid>
      <source url="https://www.reddit.com/r/MachineLearning/comments/1r5ogo5/put_a_neural_network_in_vcv_rack_2_and_told_it_to/">r/MachineLearning</source>
    </item>
    <item>
      <title>Show HN: Microgpt is a GPT you can visualize in the browser</title>
      <link>https://microgpt.boratto.ca</link>
      <description><![CDATA[very much inspired by karpathy's microgpt of the same name. it's (by default) a 4000 param GPT/LLM/NN that learns to generate names. this is sorta an educational tool in that you can visualize the activations as they pass through the network, and click on things to get an…]]></description>
      <pubDate>Sun, 15 Feb 2026 18:40:35 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://microgpt.boratto.ca</guid>
      <source url="https://microgpt.boratto.ca">Hacker News AI</source>
    </item>
    <item>
      <title>How to run Qwen3-Coder-Next 80b parameters model on 8Gb VRAM</title>
      <link>https://www.reddit.com/r/LocalLLaMA/comments/1r5m4vl/how_to_run_qwen3codernext_80b_parameters_model_on/</link>
      <description><![CDATA[I am running large llms on my 8Gb laptop 3070ti. I have optimized: LTX-2, Wan2.2, HeartMula, ACE-STEP 1.5. And now i abble to run 80b parameters model Qwen3-Coder-Next !!! Instruction here: https://github.com/nalexand/Qwen3-Coder-OPTIMIZED It is FP8 quant 80Gb in size, it is…]]></description>
      <pubDate>Sun, 15 Feb 2026 18:33:14 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://www.reddit.com/r/LocalLLaMA/comments/1r5m4vl/how_to_run_qwen3codernext_80b_parameters_model_on/</guid>
      <source url="https://www.reddit.com/r/LocalLLaMA/comments/1r5m4vl/how_to_run_qwen3codernext_80b_parameters_model_on/">r/LocalLLaMA</source>
    </item>
    <item>
      <title>Bad Apple but it&apos;s GPT-2 XL Attention Maps</title>
      <link>https://www.reddit.com/r/LocalLLaMA/comments/1r5lra1/bad_apple_but_its_gpt2_xl_attention_maps/</link>
      <description><![CDATA[I optimized learnable input embeddings for a frozen GPT-2 XL model so that its attention maps display the frames of the Bad Apple music video. The model never saw an image in its life, The optimizer just found the right inputs. This is a silly little project but I found it…]]></description>
      <pubDate>Sun, 15 Feb 2026 18:19:02 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://www.reddit.com/r/LocalLLaMA/comments/1r5lra1/bad_apple_but_its_gpt2_xl_attention_maps/</guid>
      <source url="https://www.reddit.com/r/LocalLLaMA/comments/1r5lra1/bad_apple_but_its_gpt2_xl_attention_maps/">r/LocalLLaMA</source>
    </item>
    <item>
      <title>8 Best Generative Engine Optimisation (GEO) Agencies in Australia for 2026 - Talons Marketing</title>
      <link>https://talonsmarketing.com.au/8-best-generative-engine-optimisation-geo-agencies-australia/</link>
      <description><![CDATA[Aligning local SEO signals with generative search results · Their GEO strategy is particularly strong for local businesses, service providers, and multi-location brands that need to appear in AI answers like “best provider near me” or “recommended service in Melbourne.”]]></description>
      <pubDate>Sat, 28 Feb 2026 08:03:12 GMT</pubDate>
      <category>Industry &amp; Business</category>
      <guid isPermaLink="true">https://talonsmarketing.com.au/8-best-generative-engine-optimisation-geo-agencies-australia/</guid>
      <source url="https://talonsmarketing.com.au/8-best-generative-engine-optimisation-geo-agencies-australia/">Brave Search</source>
    </item>
    <item>
      <title>If you were starting with local LLMs today, what would you do differently</title>
      <link>https://www.reddit.com/r/LocalLLaMA/comments/1r5k46x/if_you_were_starting_with_local_llms_today_what/</link>
      <description><![CDATA[Hey all, I am seriously considering investing a significant portion of my signing bonus into a local LLM setup as a hobby and learning project once I start my job in August. I am currently in university. I have studied a lot of theory, but I feel I am missing practical, hands-on…]]></description>
      <pubDate>Sun, 15 Feb 2026 17:15:44 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://www.reddit.com/r/LocalLLaMA/comments/1r5k46x/if_you_were_starting_with_local_llms_today_what/</guid>
      <source url="https://www.reddit.com/r/LocalLLaMA/comments/1r5k46x/if_you_were_starting_with_local_llms_today_what/">r/LocalLLaMA</source>
    </item>
    <item>
      <title>@unknown: @ExpressTechie Nice move by Anthropic. Use the new Claude free features for low-...</title>
      <link>https://x.com/unknown/status/2022219269212131810</link>
      <description><![CDATA[@ExpressTechie Nice move by Anthropic. Use the new Claude free features for low-risk tasks, keep premium models for critical paths. Routing makes that split clean. Gatewayz lets you switch per request without rewrites.]]></description>
      <pubDate>Fri, 13 Feb 2026 08:00:19 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022219269212131810</guid>
      <source url="https://x.com/unknown/status/2022219269212131810">X/@unknown</source>
    </item>
    <item>
      <title>@unknown: @GytisT @pcstyle53 @windsurf @OpenAI he says was fixed earlier today and sorry, ...</title>
      <link>https://x.com/unknown/status/2022219053004394739</link>
      <description><![CDATA[@GytisT @pcstyle53 @windsurf @OpenAI he says was fixed earlier today and sorry, please do send other bugs (if a lot feel free to compile a gdoc) https://t.co/VVGkJBqkx7]]></description>
      <pubDate>Fri, 13 Feb 2026 07:59:27 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022219053004394739</guid>
      <source url="https://x.com/unknown/status/2022219053004394739">X/@unknown</source>
    </item>
    <item>
      <title>@unknown: 記錄一下：
claudian配置antigravity tools 產生的api
ANTHROPIC_AUTH_TOKEN=sk-xxx
ANTHROPIC_A...</title>
      <link>https://x.com/unknown/status/2022217932546396520</link>
      <description><![CDATA[記錄一下：
claudian配置antigravity tools 產生的api
ANTHROPIC_AUTH_TOKEN=sk-xxx
ANTHROPIC_API_KEY=""
ANTHROPIC_BASE_URL=http://localhost:8045
ANTHROPIC_DEFAULT_OPUS_MODEL=claude-opus-4-6-thinking

接入完成。
不知道用第三方antigravity tools，會不會被Google懲罰！ https://t.co/tCE02hJT0Z]]></description>
      <pubDate>Fri, 13 Feb 2026 07:55:00 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022217932546396520</guid>
      <source url="https://x.com/unknown/status/2022217932546396520">X/@unknown</source>
    </item>
    <item>
      <title>@unknown: @GergelyOrosz @simonw @grinich @WorkOS @bcantrill michael at aie: https://t.co/U...</title>
      <link>https://x.com/unknown/status/2022217788337828283</link>
      <description><![CDATA[@GergelyOrosz @simonw @grinich @WorkOS @bcantrill michael at aie: https://t.co/UPiHushX1I

we need to give a bigger update at WF this year]]></description>
      <pubDate>Fri, 13 Feb 2026 07:54:26 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022217788337828283</guid>
      <source url="https://x.com/unknown/status/2022217788337828283">X/@unknown</source>
    </item>
    <item>
      <title>@unknown: I find @grok is meaningfully worse then ChatGPT and Gemini for most things...</title>
      <link>https://x.com/unknown/status/2022214040236568891</link>
      <description><![CDATA[I find @grok is meaningfully worse then ChatGPT and Gemini for most things]]></description>
      <pubDate>Fri, 13 Feb 2026 07:39:32 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022214040236568891</guid>
      <source url="https://x.com/unknown/status/2022214040236568891">X/@unknown</source>
    </item>
    <item>
      <title>@unknown: had a lovely @GergelyOrosz dinner with fellow tech writers and I found myself pa...</title>
      <link>https://x.com/unknown/status/2022193296819597671</link>
      <description><![CDATA[had a lovely @GergelyOrosz dinner with fellow tech writers and I found myself passionately recommending @simonw some underrated talks,

You should watch:
- @grinich’s founding thesis for @WorkOS 
- @bcantrill’s talk on picking tech based on values they espouse

finding and…]]></description>
      <pubDate>Fri, 13 Feb 2026 06:17:07 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022193296819597671</guid>
      <source url="https://x.com/unknown/status/2022193296819597671">X/@unknown</source>
    </item>
    <item>
      <title>@unknown: A schizophrenic cult has emerged around ChatGPT 4o, and the psychosis will only ...</title>
      <link>https://x.com/unknown/status/2022188079377957000</link>
      <description><![CDATA[A schizophrenic cult has emerged around ChatGPT 4o, and the psychosis will only get worse]]></description>
      <pubDate>Fri, 13 Feb 2026 05:56:23 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022188079377957000</guid>
      <source url="https://x.com/unknown/status/2022188079377957000">X/@unknown</source>
    </item>
    <item>
      <title>@unknown: I guarantee if you catch this woman off guard and ask her who Hobbes was, you wi...</title>
      <link>https://x.com/unknown/status/2022181866133237966</link>
      <description><![CDATA[I guarantee if you catch this woman off guard and ask her who Hobbes was, you will be met with the blankest emptiest expression ever
Even worse than the one she has on her face in this chatgpt-fueled video.]]></description>
      <pubDate>Fri, 13 Feb 2026 05:31:41 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022181866133237966</guid>
      <source url="https://x.com/unknown/status/2022181866133237966">X/@unknown</source>
    </item>
    <item>
      <title>[R] Has anyone experimented with MHC on traditional autoencoders/convolutional architectures?</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1r3gqng/r_has_anyone_experimented_with_mhc_on_traditional/</link>
      <description><![CDATA[I'm currently making a baseline autoencoder for this super freaking huge hyperspectral image dataset I have. It's a really big pain to work with and to get decent results, and I had to basically pull all stops including using ResNeXt2, channel-by-channel processing and grouping,…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:27:06 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://www.reddit.com/r/MachineLearning/comments/1r3gqng/r_has_anyone_experimented_with_mhc_on_traditional/</guid>
      <source url="https://www.reddit.com/r/MachineLearning/comments/1r3gqng/r_has_anyone_experimented_with_mhc_on_traditional/">r/MachineLearning</source>
    </item>
    <item>
      <title>@unknown: Stop hiring executors and start training supervisors. AI shouldn’t just speed up...</title>
      <link>https://x.com/unknown/status/2022175312675823649</link>
      <description><![CDATA[Stop hiring executors and start training supervisors. AI shouldn’t just speed up broken processes; it should handle the routine while your people manage the complex. Shift to Human-over-the-loop and turn your team into an elite supervisory layer.

https://t.co/ViCi4srrdz…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:05:39 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022175312675823649</guid>
      <source url="https://x.com/unknown/status/2022175312675823649">X/@unknown</source>
    </item>
    <item>
      <title>Assessing LLM Reliability on Temporally Recent Open-Domain Questions</title>
      <link>https://arxiv.org/abs/2602.11165</link>
      <description><![CDATA[arXiv:2602.11165v1 Announce Type: new Abstract: Large Language Models (LLMs) are increasingly deployed for open-domain question answering, yet their alignment with human perspectives on temporally recent information remains underexplored. We introduce RECOM (Reddit Evaluation…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11165</guid>
      <source url="https://arxiv.org/abs/2602.11165">arXiv cs.CL</source>
    </item>
    <item>
      <title>Latent Generative Solvers for Generalizable Long-Term Physics Simulation</title>
      <link>https://arxiv.org/abs/2602.11229</link>
      <description><![CDATA[arXiv:2602.11229v1 Announce Type: new Abstract: We study long-horizon surrogate simulation across heterogeneous PDE systems. We introduce Latent Generative Solvers (LGS), a two-stage framework that (i) maps diverse PDE states into a shared latent physics space with a pretrained…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11229</guid>
      <source url="https://arxiv.org/abs/2602.11229">arXiv cs.AI</source>
    </item>
    <item>
      <title>Bi-Level Prompt Optimization for Multimodal LLM-as-a-Judge</title>
      <link>https://arxiv.org/abs/2602.11340</link>
      <description><![CDATA[arXiv:2602.11340v1 Announce Type: new Abstract: Large language models (LLMs) have become widely adopted as automated judges for evaluating AI-generated content. Despite their success, aligning LLM-based evaluations with human judgments remains challenging. While supervised…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11340</guid>
      <source url="https://arxiv.org/abs/2602.11340">arXiv cs.AI</source>
    </item>
    <item>
      <title>AgentNoiseBench: Benchmarking Robustness of Tool-Using LLM Agents Under Noisy Condition</title>
      <link>https://arxiv.org/abs/2602.11348</link>
      <description><![CDATA[arXiv:2602.11348v1 Announce Type: new Abstract: Recent advances in large language models have enabled LLM-based agents to achieve strong performance on a variety of benchmarks. However, their performance in real-world deployments often that observed on benchmark settings,…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11348</guid>
      <source url="https://arxiv.org/abs/2602.11348">arXiv cs.AI</source>
    </item>
    <item>
      <title>Pushing Forward Pareto Frontiers of Proactive Agents with Behavioral Agentic Optimization</title>
      <link>https://arxiv.org/abs/2602.11351</link>
      <description><![CDATA[arXiv:2602.11351v1 Announce Type: new Abstract: Proactive large language model (LLM) agents aim to actively plan, query, and interact over multiple turns, enabling efficient task completion beyond passive instruction following and making them essential for real-world,…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11351</guid>
      <source url="https://arxiv.org/abs/2602.11351">arXiv cs.AI</source>
    </item>
    <item>
      <title>Response-Based Knowledge Distillation for Multilingual Jailbreak Prevention Unwittingly Compromises Safety</title>
      <link>https://arxiv.org/abs/2602.11157</link>
      <description><![CDATA[arXiv:2602.11157v1 Announce Type: new Abstract: Large language models (LLMs) are increasingly deployed worldwide, yet their safety alignment remains predominantly English-centric. This allows for vulnerabilities in non-English contexts, especially with low-resource languages. We…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11157</guid>
      <source url="https://arxiv.org/abs/2602.11157">arXiv cs.CL</source>
    </item>
    <item>
      <title>Visualizing and Benchmarking LLM Factual Hallucination Tendencies via Internal State Analysis and Clustering</title>
      <link>https://arxiv.org/abs/2602.11167</link>
      <description><![CDATA[arXiv:2602.11167v1 Announce Type: new Abstract: Large Language Models (LLMs) often hallucinate, generating nonsensical or false information that can be especially harmful in sensitive fields such as medicine or law. To study this phenomenon systematically, we introduce…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11167</guid>
      <source url="https://arxiv.org/abs/2602.11167">arXiv cs.CL</source>
    </item>
    <item>
      <title>Explaining AI Without Code: A User Study on Explainable AI</title>
      <link>https://arxiv.org/abs/2602.11159</link>
      <description><![CDATA[arXiv:2602.11159v1 Announce Type: new Abstract: The increasing use of Machine Learning (ML) in sensitive domains such as healthcare, finance, and public policy has raised concerns about the transparency of automated decisions. Explainable AI (XAI) addresses this by clarifying…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11159</guid>
      <source url="https://arxiv.org/abs/2602.11159">arXiv cs.AI</source>
    </item>
    <item>
      <title>Dissecting Subjectivity and the &quot;Ground Truth&quot; Illusion in Data Annotation</title>
      <link>https://arxiv.org/abs/2602.11318</link>
      <description><![CDATA[arXiv:2602.11318v1 Announce Type: new Abstract: In machine learning, "ground truth" refers to the assumed correct labels used to train and evaluate models. However, the foundational "ground truth" paradigm rests on a positivistic fallacy that treats human disagreement as…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11318</guid>
      <source url="https://arxiv.org/abs/2602.11318">arXiv cs.AI</source>
    </item>
    <item>
      <title>TRACER: Trajectory Risk Aggregation for Critical Episodes in Agentic Reasoning</title>
      <link>https://arxiv.org/abs/2602.11409</link>
      <description><![CDATA[arXiv:2602.11409v1 Announce Type: new Abstract: Estimating uncertainty for AI agents in real-world multi-turn tool-using interaction with humans is difficult because failures are often triggered by sparse critical episodes (e.g., looping, incoherent tool use, or user-agent…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11409</guid>
      <source url="https://arxiv.org/abs/2602.11409">arXiv cs.AI</source>
    </item>
    <item>
      <title>Distributionally Robust Cooperative Multi-Agent Reinforcement Learning via Robust Value Factorization</title>
      <link>https://arxiv.org/abs/2602.11437</link>
      <description><![CDATA[arXiv:2602.11437v1 Announce Type: new Abstract: Cooperative multi-agent reinforcement learning (MARL) commonly adopts centralized training with decentralized execution, where value-factorization methods enforce the individual-global-maximum (IGM) principle so that decentralized…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11437</guid>
      <source url="https://arxiv.org/abs/2602.11437">arXiv cs.AI</source>
    </item>
    <item>
      <title>Credit Where It is Due: Cross-Modality Connectivity Drives Precise Reinforcement Learning for MLLM Reasoning</title>
      <link>https://arxiv.org/abs/2602.11455</link>
      <description><![CDATA[arXiv:2602.11455v1 Announce Type: new Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has significantly advanced the reasoning capabilities of Multimodal Large Language Models (MLLMs), yet how visual evidence is integrated during reasoning remains poorly…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Image &amp; Video Generation</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11455</guid>
      <source url="https://arxiv.org/abs/2602.11455">arXiv cs.AI</source>
    </item>
    <item>
      <title>Retrieval Heads are Dynamic</title>
      <link>https://arxiv.org/abs/2602.11162</link>
      <description><![CDATA[arXiv:2602.11162v1 Announce Type: new Abstract: Recent studies have identified "retrieval heads" in Large Language Models (LLMs) responsible for extracting information from input contexts. However, prior works largely rely on static statistics aggregated across datasets,…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11162</guid>
      <source url="https://arxiv.org/abs/2602.11162">arXiv cs.CL</source>
    </item>
    <item>
      <title>Small Updates, Big Doubts: Does Parameter-Efficient Fine-tuning Enhance Hallucination Detection ?</title>
      <link>https://arxiv.org/abs/2602.11166</link>
      <description><![CDATA[arXiv:2602.11166v1 Announce Type: new Abstract: Parameter-efficient fine-tuning (PEFT) methods are widely used to adapt large language models (LLMs) to downstream tasks and are often assumed to improve factual correctness. However, how the parameter-efficient fine-tuning methods…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11166</guid>
      <source url="https://arxiv.org/abs/2602.11166">arXiv cs.CL</source>
    </item>
    <item>
      <title>Enhancing SDG-Text Classification with Combinatorial Fusion Analysis and Generative AI</title>
      <link>https://arxiv.org/abs/2602.11168</link>
      <description><![CDATA[arXiv:2602.11168v1 Announce Type: new Abstract: (Natural Language Processing) NLP techniques such as text classification and topic discovery are very useful in many application areas including information retrieval, knowledge discovery, policy formulation, and decision-making.…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11168</guid>
      <source url="https://arxiv.org/abs/2602.11168">arXiv cs.CL</source>
    </item>
    <item>
      <title>Disentangling Direction and Magnitude in Transformer Representations: A Double Dissociation Through L2-Matched Perturbation Analysis</title>
      <link>https://arxiv.org/abs/2602.11169</link>
      <description><![CDATA[arXiv:2602.11169v1 Announce Type: new Abstract: Transformer hidden states encode information as high-dimensional vectors, yet whether direction (orientation in representational space) and magnitude (vector norm) serve distinct functional roles remains unclear. Studying…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11169</guid>
      <source url="https://arxiv.org/abs/2602.11169">arXiv cs.CL</source>
    </item>
    <item>
      <title>PRIME: Policy-Reinforced Iterative Multi-agent Execution for Algorithmic Reasoning in Large Language Models</title>
      <link>https://arxiv.org/abs/2602.11170</link>
      <description><![CDATA[arXiv:2602.11170v1 Announce Type: new Abstract: Large language models have demonstrated remarkable capabilities across diverse reasoning tasks, yet their performance on algorithmic reasoning remains limited. To handle this limitation, we propose PRIME (Policy-Reinforced…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11170</guid>
      <source url="https://arxiv.org/abs/2602.11170">arXiv cs.CL</source>
    </item>
    <item>
      <title>Efficient Hyper-Parameter Search for LoRA via Language-aided Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2602.11171</link>
      <description><![CDATA[arXiv:2602.11171v1 Announce Type: new Abstract: Fine-tuning Large Language Models (LLMs) with Low-Rank Adaptation (LoRA) enables resource-efficient personalization or specialization, but it comes at the expense of additional hyperparameter tuning. Although LoRA makes fine-tuning…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11171</guid>
      <source url="https://arxiv.org/abs/2602.11171">arXiv cs.CL</source>
    </item>
    <item>
      <title>Synthesizing the Virtual Advocate: A Multi-Persona Speech Generation Framework for Diverse Linguistic Jurisdictions in Indic Languages</title>
      <link>https://arxiv.org/abs/2602.11172</link>
      <description><![CDATA[arXiv:2602.11172v1 Announce Type: new Abstract: Legal advocacy requires a unique combination of authoritative tone, rhythmic pausing for emphasis, and emotional intelligence. This study investigates the performance of the Gemini 2.5 Flash TTS and Gemini 2.5 Pro TTS models in…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Voice &amp; Audio</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11172</guid>
      <source url="https://arxiv.org/abs/2602.11172">arXiv cs.CL</source>
    </item>
    <item>
      <title>Barriers to Discrete Reasoning with Transformers: A Survey Across Depth, Exactness, and Bandwidth</title>
      <link>https://arxiv.org/abs/2602.11175</link>
      <description><![CDATA[arXiv:2602.11175v1 Announce Type: new Abstract: Transformers have become the foundational architecture for a broad spectrum of sequence modeling applications, underpinning state-of-the-art systems in natural language processing, vision, and beyond. However, their theoretical…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11175</guid>
      <source url="https://arxiv.org/abs/2602.11175">arXiv cs.CL</source>
    </item>
    <item>
      <title>Voxtral Realtime</title>
      <link>https://arxiv.org/abs/2602.11298</link>
      <description><![CDATA[arXiv:2602.11298v1 Announce Type: new Abstract: We introduce Voxtral Realtime, a natively streaming automatic speech recognition model that matches offline transcription quality at sub-second latency. Unlike approaches that adapt offline models through chunking or sliding…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Voice &amp; Audio</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11298</guid>
      <source url="https://arxiv.org/abs/2602.11298">arXiv cs.AI</source>
    </item>
    <item>
      <title>GHOST: Unmasking Phantom States in Mamba2 via Grouped Hidden-state Output-aware Selection &amp; Truncation</title>
      <link>https://arxiv.org/abs/2602.11408</link>
      <description><![CDATA[arXiv:2602.11408v1 Announce Type: new Abstract: While Mamba2's expanded state dimension enhances temporal modeling, it incurs substantial inference overhead that saturates bandwidth during autoregressive generation. Standard pruning methods fail to address this bottleneck:…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11408</guid>
      <source url="https://arxiv.org/abs/2602.11408">arXiv cs.AI</source>
    </item>
    <item>
      <title>HybridRAG: A Practical LLM-based ChatBot Framework based on Pre-Generated Q&amp;A over Raw Unstructured Documents</title>
      <link>https://arxiv.org/abs/2602.11156</link>
      <description><![CDATA[arXiv:2602.11156v1 Announce Type: new Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful approach for grounding Large Language Model (LLM)-based chatbot responses on external knowledge. However, existing RAG studies typically assume well-structured textual…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11156</guid>
      <source url="https://arxiv.org/abs/2602.11156">arXiv cs.CL</source>
    </item>
    <item>
      <title>Nested Named Entity Recognition in Plasma Physics Research Articles</title>
      <link>https://arxiv.org/abs/2602.11163</link>
      <description><![CDATA[arXiv:2602.11163v1 Announce Type: new Abstract: Named Entity Recognition (NER) is an important task in natural language processing that aims to identify and extract key entities from unstructured text. We present a novel application of NER in plasma physics research articles and…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11163</guid>
      <source url="https://arxiv.org/abs/2602.11163">arXiv cs.CL</source>
    </item>
    <item>
      <title>Author-in-the-Loop Response Generation and Evaluation: Integrating Author Expertise and Intent in Responses to Peer Review</title>
      <link>https://arxiv.org/abs/2602.11173</link>
      <description><![CDATA[arXiv:2602.11173v1 Announce Type: new Abstract: Author response (rebuttal) writing is a critical stage of scientific peer review that demands substantial author effort. Recent work frames this task as automatic text generation, underusing author expertise and intent. In…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11173</guid>
      <source url="https://arxiv.org/abs/2602.11173">arXiv cs.CL</source>
    </item>
    <item>
      <title>The Script Tax: Measuring Tokenization-Driven Efficiency and Latency Disparities in Multilingual Language Models</title>
      <link>https://arxiv.org/abs/2602.11174</link>
      <description><![CDATA[arXiv:2602.11174v1 Announce Type: new Abstract: Pretrained multilingual language models are often assumed to be script-agnostic, yet their tokenizers can impose systematic costs on certain writing systems. We quantify this script tax by comparing two orthographic variants with…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11174</guid>
      <source url="https://arxiv.org/abs/2602.11174">arXiv cs.CL</source>
    </item>
    <item>
      <title>GAC-KAN: An Ultra-Lightweight GNSS Interference Classifier for GenAI-Powered Consumer Edge Devices</title>
      <link>https://arxiv.org/abs/2602.11186</link>
      <description><![CDATA[arXiv:2602.11186v1 Announce Type: new Abstract: The integration of Generative AI (GenAI) into Consumer Electronics (CE)--from AI-powered assistants in wearables to generative planning in autonomous Uncrewed Aerial Vehicles (UAVs)--has revolutionized user experiences. However,…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11186</guid>
      <source url="https://arxiv.org/abs/2602.11186">arXiv cs.LG</source>
    </item>
    <item>
      <title>Automated Optimization Modeling via a Localizable Error-Driven Perspective</title>
      <link>https://arxiv.org/abs/2602.11164</link>
      <description><![CDATA[arXiv:2602.11164v1 Announce Type: new Abstract: Automated optimization modeling via Large Language Models (LLMs) has emerged as a promising approach to assist complex human decision-making. While post-training has become a pivotal technique to enhance LLMs' capabilities in this…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11164</guid>
      <source url="https://arxiv.org/abs/2602.11164">arXiv cs.LG</source>
    </item>
    <item>
      <title>KBVQ-MoE: KLT-guided SVD with Bias-Corrected Vector Quantization for MoE Large Language Models</title>
      <link>https://arxiv.org/abs/2602.11184</link>
      <description><![CDATA[arXiv:2602.11184v1 Announce Type: new Abstract: Mixture of Experts (MoE) models have achieved great success by significantly improving performance while maintaining computational efficiency through sparse expert activation. However, their enormous parameter sizes and memory…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11184</guid>
      <source url="https://arxiv.org/abs/2602.11184">arXiv cs.LG</source>
    </item>
    <item>
      <title>Spectra: Rethinking Optimizers for LLMs Under Spectral Anisotropy</title>
      <link>https://arxiv.org/abs/2602.11185</link>
      <description><![CDATA[arXiv:2602.11185v1 Announce Type: new Abstract: Gradient signals in LLM training are highly anisotropic: recurrent linguistic structure concentrates energy into a small set of dominant spectral directions, while context specific information resides in a long tail. We show that…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11185</guid>
      <source url="https://arxiv.org/abs/2602.11185">arXiv cs.LG</source>
    </item>
    <item>
      <title>Predicting the post-wildfire mudflow onset using machine learning models on multi-parameter experimental data</title>
      <link>https://arxiv.org/abs/2602.11194</link>
      <description><![CDATA[arXiv:2602.11194v1 Announce Type: new Abstract: Post-wildfire mudflows are increasingly hazardous due to the prevalence of wildfires, including those on the wildland-urban interface. Upon burning, soil on the surface or immediately beneath becomes hydrophobic, a phenomenon that…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11194</guid>
      <source url="https://arxiv.org/abs/2602.11194">arXiv cs.LG</source>
    </item>
    <item>
      <title>Charting Empirical Laws for LLM Fine-Tuning in Scientific Multi-Discipline Learning</title>
      <link>https://arxiv.org/abs/2602.11215</link>
      <description><![CDATA[arXiv:2602.11215v1 Announce Type: new Abstract: While large language models (LLMs) have achieved strong performance through fine-tuning within individual scientific domains, their learning dynamics in multi-disciplinary contexts remains poorly understood, despite the promise of…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11215</guid>
      <source url="https://arxiv.org/abs/2602.11215">arXiv cs.LG</source>
    </item>
    <item>
      <title>TDPNavigator-Placer: Thermal- and Wirelength-Aware Chiplet Placement in 2.5D Systems Through Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2602.11187</link>
      <description><![CDATA[arXiv:2602.11187v1 Announce Type: new Abstract: The rapid growth of electronics has accelerated the adoption of 2.5D integrated circuits, where effective automated chiplet placement is essential as systems scale to larger and more heterogeneous chiplet assemblies. Existing…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11187</guid>
      <source url="https://arxiv.org/abs/2602.11187">arXiv cs.LG</source>
    </item>
    <item>
      <title>Time-TK: A Multi-Offset Temporal Interaction Framework Combining Transformer and Kolmogorov-Arnold Networks for Time Series Forecasting</title>
      <link>https://arxiv.org/abs/2602.11190</link>
      <description><![CDATA[arXiv:2602.11190v1 Announce Type: new Abstract: Time series forecasting is crucial for the World Wide Web and represents a core technical challenge in ensuring the stable and efficient operation of modern web services, such as intelligent transportation and website throughput.…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11190</guid>
      <source url="https://arxiv.org/abs/2602.11190">arXiv cs.LG</source>
    </item>
    <item>
      <title>MELINOE: Fine-Tuning Enables Memory-Efficient Inference for Mixture-of-Experts Models</title>
      <link>https://arxiv.org/abs/2602.11192</link>
      <description><![CDATA[arXiv:2602.11192v1 Announce Type: new Abstract: Mixture-of-Experts (MoE) model architectures can significantly reduce the number of activated parameters per token, enabling computationally efficient training and inference. However, their large overall parameter counts and model…]]></description>
      <pubDate>Fri, 13 Feb 2026 05:00:00 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.11192</guid>
      <source url="https://arxiv.org/abs/2602.11192">arXiv cs.LG</source>
    </item>
    <item>
      <title>@unknown: To give credit to the economists, these two papers from early 2023 (by @danielro...</title>
      <link>https://x.com/unknown/status/2022160521366319297</link>
      <description><![CDATA[To give credit to the economists, these two papers from early 2023 (by @danielrock, @robseamans and others who I am not sure are still on X) did a great job forecasting which jobs would turn out to be most exposed to AI using O*NET, and they were written during the GPT-3.5 era.…]]></description>
      <pubDate>Fri, 13 Feb 2026 04:06:52 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022160521366319297</guid>
      <source url="https://x.com/unknown/status/2022160521366319297">X/@unknown</source>
    </item>
    <item>
      <title>@unknown: I’m impressed both by the quality of the pelican and that “SVG of a pelican ridi...</title>
      <link>https://x.com/unknown/status/2022143097841627295</link>
      <description><![CDATA[I’m impressed both by the quality of the pelican and that “SVG of a pelican riding a bicycle” remains an unsaturated benchmark — surprisingly high ceiling on this task]]></description>
      <pubDate>Fri, 13 Feb 2026 02:57:38 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022143097841627295</guid>
      <source url="https://x.com/unknown/status/2022143097841627295">X/@unknown</source>
    </item>
    <item>
      <title>@unknown: @hooyahdeepsea69 @newstart_2024 Galloway&apos;s pod clip nails AI&apos;s hype vs. reality—...</title>
      <link>https://x.com/unknown/status/2022142481488355472</link>
      <description><![CDATA[@hooyahdeepsea69 @newstart_2024 Galloway's pod clip nails AI's hype vs. reality—job displacement, quality dips for cost cuts, welfare strains. In abundance era, this risks Mouse Utopia's decay without ethical AI blueprints for fair automation. How'd you blueprint safeguards…]]></description>
      <pubDate>Fri, 13 Feb 2026 02:55:11 GMT</pubDate>
      <category>Strategy &amp; Opinion</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022142481488355472</guid>
      <source url="https://x.com/unknown/status/2022142481488355472">X/@unknown</source>
    </item>
    <item>
      <title>@unknown: I am surprised that we don’t see more governments and non-profits going all-in o...</title>
      <link>https://x.com/unknown/status/2022130014712741900</link>
      <description><![CDATA[I am surprised that we don’t see more governments and non-profits going all-in on transformational AI use cases for good. There are areas like journalism &amp; education where funding ambitious, civic-minded &amp; context-sensitive moonshots could make a difference and empower…]]></description>
      <pubDate>Fri, 13 Feb 2026 02:05:39 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022130014712741900</guid>
      <source url="https://x.com/unknown/status/2022130014712741900">X/@unknown</source>
    </item>
    <item>
      <title>@unknown: Rather than converting everything into random benchmark numbers that humans have...</title>
      <link>https://x.com/unknown/status/2022118940168831302</link>
      <description><![CDATA[Rather than converting everything into random benchmark numbers that humans have no comparisons for, we should just use D&amp;D stat blocks for AI (CHR, INT, WIS) and robots (STR, DEX, CON). You then can do reasonable comparisons like whether any given AI can outsmart a beholder.]]></description>
      <pubDate>Fri, 13 Feb 2026 01:21:39 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022118940168831302</guid>
      <source url="https://x.com/unknown/status/2022118940168831302">X/@unknown</source>
    </item>
    <item>
      <title>@unknown: The differentiation between long running agents and in-the-moment agents, that p...</title>
      <link>https://x.com/unknown/status/2022106144622408182</link>
      <description><![CDATA[The differentiation between long running agents and in-the-moment agents, that preform a realtime assistant - is a big deal. 
It will integrate into  development habits quickly while long running agents works isolated 
Love it 

https://t.co/OiU3uBUmDr]]></description>
      <pubDate>Fri, 13 Feb 2026 00:30:48 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022106144622408182</guid>
      <source url="https://x.com/unknown/status/2022106144622408182">X/@unknown</source>
    </item>
    <item>
      <title>@unknown: AI is moving so fast that we’re all living in ambiguity: hype vs reality.
What w...</title>
      <link>https://x.com/unknown/status/2022103474075533496</link>
      <description><![CDATA[AI is moving so fast that we’re all living in ambiguity: hype vs reality.
What will be the safest job in terms of next 5 years?]]></description>
      <pubDate>Fri, 13 Feb 2026 00:20:11 GMT</pubDate>
      <category>Strategy &amp; Opinion</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022103474075533496</guid>
      <source url="https://x.com/unknown/status/2022103474075533496">X/@unknown</source>
    </item>
    <item>
      <title>@unknown: AI video isn’t a feature race anymore — it’s a market war.

Who’s actually winni...</title>
      <link>https://x.com/unknown/status/2022098644510384294</link>
      <description><![CDATA[AI video isn’t a feature race anymore — it’s a market war.

Who’s actually winning on users, downloads, and daily active engagement in 2026?

- #Seedance 2.0. 
- #Sora 2. 
- #Kling 3.0. 
- #Runway Gen-4.5.

The real story isn’t quality — it’s scale. 👇
https://t.co/96czeA56TJ]]></description>
      <pubDate>Fri, 13 Feb 2026 00:01:00 GMT</pubDate>
      <category>Image &amp; Video Generation</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022098644510384294</guid>
      <source url="https://x.com/unknown/status/2022098644510384294">X/@unknown</source>
    </item>
    <item>
      <title>Amid disappointing earnings, Pinterest claims it sees more searches than ChatGPT</title>
      <link>https://techcrunch.com/2026/02/12/amid-disappointing-earnings-pinterest-claims-it-sees-more-searches-than-chatgpt/</link>
      <description><![CDATA[Pinterest's stock tumbles after an earnings miss, with higher-than-expected usage its only bright spot.]]></description>
      <pubDate>Thu, 12 Feb 2026 23:26:56 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://techcrunch.com/2026/02/12/amid-disappointing-earnings-pinterest-claims-it-sees-more-searches-than-chatgpt/</guid>
      <source url="https://techcrunch.com/2026/02/12/amid-disappointing-earnings-pinterest-claims-it-sees-more-searches-than-chatgpt/">TechCrunch AI</source>
    </item>
    <item>
      <title>IBM will hire your entry-level talent in the age of AI</title>
      <link>https://techcrunch.com/2026/02/12/ibm-will-hire-your-entry-level-talent-in-the-age-of-ai/</link>
      <description><![CDATA[IBM plans to triple its entry-level hiring in the U.S. in 2026, but these jobs will have different tasks than in previous years.]]></description>
      <pubDate>Thu, 12 Feb 2026 23:23:17 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://techcrunch.com/2026/02/12/ibm-will-hire-your-entry-level-talent-in-the-age-of-ai/</guid>
      <source url="https://techcrunch.com/2026/02/12/ibm-will-hire-your-entry-level-talent-in-the-age-of-ai/">TechCrunch AI</source>
    </item>
    <item>
      <title>OpenAI sidesteps Nvidia with unusually fast coding model on plate-sized chips</title>
      <link>https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/</link>
      <description><![CDATA[OpenAI's new GPT‑5.3‑Codex‑Spark is 15 times faster at coding than its predecessor.]]></description>
      <pubDate>Thu, 12 Feb 2026 22:56:02 GMT</pubDate>
      <category>AI Coding &amp; Agents</category>
      <guid isPermaLink="true">https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/</guid>
      <source url="https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/">Ars Technica AI</source>
    </item>
    <item>
      <title>[P] ML training cluster for university students</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1r388tr/p_ml_training_cluster_for_university_students/</link>
      <description><![CDATA[Hi! I'm an exec at a University AI research club. We are trying to build a gpu cluster for our student body so they can have reliable access to compute, but we aren't sure where to start. Our goal is to have a cluster that can be improved later on - i.e. expand it with more…]]></description>
      <pubDate>Thu, 12 Feb 2026 22:55:04 GMT</pubDate>
      <category>Research &amp; Papers</category>
      <guid isPermaLink="true">https://www.reddit.com/r/MachineLearning/comments/1r388tr/p_ml_training_cluster_for_university_students/</guid>
      <source url="https://www.reddit.com/r/MachineLearning/comments/1r388tr/p_ml_training_cluster_for_university_students/">r/MachineLearning</source>
    </item>
    <item>
      <title>The Evolution of Categorization During the era of AI Programming [D]</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1r383nr/the_evolution_of_categorization_during_the_era_of/</link>
      <description><![CDATA[TL;DR - Hypothetically If the majority of code written is eventually generative, does this mean that the field of categorization will stagnate? If yes, does this have real implications; what if the future bottle neck isn't the AI or its capabilities, but antiquated ways in which…]]></description>
      <pubDate>Thu, 12 Feb 2026 22:49:21 GMT</pubDate>
      <category>Industry &amp; Business</category>
      <guid isPermaLink="true">https://www.reddit.com/r/MachineLearning/comments/1r383nr/the_evolution_of_categorization_during_the_era_of/</guid>
      <source url="https://www.reddit.com/r/MachineLearning/comments/1r383nr/the_evolution_of_categorization_during_the_era_of/">r/MachineLearning</source>
    </item>
    <item>
      <title>[D] Conformal Prediction vs naive thresholding to represent uncertainty</title>
      <link>https://www.reddit.com/r/MachineLearning/comments/1r37m2f/d_conformal_prediction_vs_naive_thresholding_to/</link>
      <description><![CDATA[So I recently found out about conformal prediction (cp). I’m still trying to understand it and implications of it for tasks like classification/anomaly detection. Say we have a knn based anomaly detector trained on non anomalous samples. I’m wondering how using something…]]></description>
      <pubDate>Thu, 12 Feb 2026 22:29:39 GMT</pubDate>
      <category>Strategy &amp; Opinion</category>
      <guid isPermaLink="true">https://www.reddit.com/r/MachineLearning/comments/1r37m2f/d_conformal_prediction_vs_naive_thresholding_to/</guid>
      <source url="https://www.reddit.com/r/MachineLearning/comments/1r37m2f/d_conformal_prediction_vs_naive_thresholding_to/">r/MachineLearning</source>
    </item>
    <item>
      <title>‘Uncanny Valley’: ICE’s Secret Expansion Plans, Palantir Workers’ Ethical Concerns, and AI Assistants</title>
      <link>https://www.wired.com/story/uncanny-valley-podcast-ice-expansion-palantir-workers-ethical-concerns-openclaw-ai-assistants/</link>
      <description><![CDATA[In this episode of Uncanny Valley, our hosts dive into WIRED’s scoop about a secret Trump administration campaign extending right into your backyard.]]></description>
      <pubDate>Thu, 12 Feb 2026 22:12:42 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://www.wired.com/story/uncanny-valley-podcast-ice-expansion-palantir-workers-ethical-concerns-openclaw-ai-assistants/</guid>
      <source url="https://www.wired.com/story/uncanny-valley-podcast-ice-expansion-palantir-workers-ethical-concerns-openclaw-ai-assistants/">Wired AI</source>
    </item>
    <item>
      <title>Musk needed a new vision for SpaceX and xAI. He landed on Moonbase Alpha.</title>
      <link>https://techcrunch.com/2026/02/12/musk-needed-a-new-vision-for-spacex-and-xai-he-landed-on-moonbase-alpha/</link>
      <description><![CDATA["I really want to see a mass driver on the moon that is shooting AI satellites into deep space."]]></description>
      <pubDate>Thu, 12 Feb 2026 22:10:55 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://techcrunch.com/2026/02/12/musk-needed-a-new-vision-for-spacex-and-xai-he-landed-on-moonbase-alpha/</guid>
      <source url="https://techcrunch.com/2026/02/12/musk-needed-a-new-vision-for-spacex-and-xai-he-landed-on-moonbase-alpha/">TechCrunch AI</source>
    </item>
    <item>
      <title>Owning the AI Pareto Frontier — Jeff Dean</title>
      <link>https://www.latent.space/p/jeffdean</link>
      <description><![CDATA[From rewriting Google&#8217;s search stack in the early 2000s to reviving sparse trillion-parameter models and co-designing TPUs with frontier ML research, Jeff Dean has quietly shaped nearly every layer of the modern AI stack.]]></description>
      <pubDate>Thu, 12 Feb 2026 22:02:35 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://www.latent.space/p/jeffdean</guid>
      <source url="https://www.latent.space/p/jeffdean">Latent Space</source>
    </item>
    <item>
      <title>@unknown: Microsoft Agent Framework: Exposing an Existing AI Agent as an MCP Tool https://...</title>
      <link>https://x.com/unknown/status/2022058956634698002</link>
      <description><![CDATA[Microsoft Agent Framework: Exposing an Existing AI Agent as an MCP Tool https://t.co/UncLCUq7WG #machinelearning #ai]]></description>
      <pubDate>Thu, 12 Feb 2026 21:23:17 GMT</pubDate>
      <category>AI Tools &amp; Platforms</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022058956634698002</guid>
      <source url="https://x.com/unknown/status/2022058956634698002">X/@unknown</source>
    </item>
    <item>
      <title>@unknown: The model is faster, the pelican isn&apos;t as good!

GPT-5.3 Codex Spark on the left...</title>
      <link>https://x.com/unknown/status/2022057896121708735</link>
      <description><![CDATA[The model is faster, the pelican isn't as good!

GPT-5.3 Codex Spark on the left, GPT-5.3 Codex 5.3 on the right - both at medium quality settings https://t.co/d9ZxLjohT3]]></description>
      <pubDate>Thu, 12 Feb 2026 21:19:05 GMT</pubDate>
      <category>AI Coding &amp; Agents</category>
      <guid isPermaLink="true">https://x.com/unknown/status/2022057896121708735</guid>
      <source url="https://x.com/unknown/status/2022057896121708735">X/@unknown</source>
    </item>
  </channel>
</rss>